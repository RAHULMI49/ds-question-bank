[
  {
    "id": 1,
    "question": "What does 'DL' stand for in the context of AI?",
    "options": {
      "A": "Data Localization",
      "B": "Deep Learning",
      "C": "Dynamic Logic",
      "D": "Digital Literacy"
    },
    "answer": "B",
    "explanation": "DL is an abbreviation for Deep Learning, a subfield of machine learning.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 2,
    "question": "Which of the following is a common activation function used in deep neural networks?",
    "options": {
      "A": "Linear",
      "B": "Sigmoid",
      "C": "Polynomial",
      "D": "Exponential"
    },
    "answer": "B",
    "explanation": "Sigmoid, ReLU, and Tanh are common activation functions in neural networks.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 3,
    "question": "What is the basic building block of a neural network?",
    "options": {
      "A": "Node (Neuron)",
      "B": "Edge",
      "C": "Layer",
      "D": "Graph"
    },
    "answer": "A",
    "explanation": "A neuron, or node, is the fundamental computational unit in a neural network.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 4,
    "question": "Which type of neural network is primarily used for image processing?",
    "options": {
      "A": "RNN",
      "B": "CNN",
      "C": "GAN",
      "D": "LSTM"
    },
    "answer": "B",
    "explanation": "Convolutional Neural Networks (CNNs) are specialized for image and video data.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 5,
    "question": "What is the role of an 'optimizer' in deep learning?",
    "options": {
      "A": "To visualize the network architecture",
      "B": "To minimize the loss function during training",
      "C": "To normalize input data",
      "D": "To select the best hyperparameters"
    },
    "answer": "B",
    "explanation": "Optimizers adjust the model's weights to minimize the defined loss function.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 6,
    "question": "Which framework is commonly used for deep learning in Python?",
    "options": {
      "A": "Scikit-learn",
      "B": "Pandas",
      "C": "TensorFlow",
      "D": "Matplotlib"
    },
    "answer": "C",
    "explanation": "TensorFlow and PyTorch are the most widely used frameworks for deep learning.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 7,
    "question": "What does 'ReLU' stand for?",
    "options": {
      "A": "Rectified Linear Unit",
      "B": "Recurrent Learning Unit",
      "C": "Relative Loss Unit",
      "D": "Random Error Linear Unit"
    },
    "answer": "A",
    "explanation": "ReLU is a popular activation function in deep learning.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 8,
    "question": "Which of these is a type of layer in a Convolutional Neural Network?",
    "options": {
      "A": "Recurrent Layer",
      "B": "Pooling Layer",
      "C": "Embedding Layer",
      "D": "Attention Layer"
    },
    "answer": "B",
    "explanation": "Pooling layers (e.g., Max Pooling) are common in CNNs for dimensionality reduction.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 9,
    "question": "What is 'overfitting' in deep learning?",
    "options": {
      "A": "When the model is too simple to capture the data patterns",
      "B": "When the model performs well on training data but poorly on unseen data",
      "C": "When the training process is too slow",
      "D": "When the learning rate is too high"
    },
    "answer": "B",
    "explanation": "Overfitting occurs when a model learns the training data too well, including noise, and fails to generalize.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 10,
    "question": "What is the main purpose of a 'loss function' in deep learning?",
    "options": {
      "A": "To display the training progress",
      "B": "To measure the error between predicted and actual values",
      "C": "To add non-linearity to the model",
      "D": "To initialize the model's weights"
    },
    "answer": "B",
    "explanation": "The loss function quantifies how 'bad' a model's prediction is compared to the true value.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 11,
    "question": "Which type of neural network is suitable for sequence data like text or time series?",
    "options": {
      "A": "MLP",
      "B": "CNN",
      "C": "RNN",
      "D": "Autoencoder"
    },
    "answer": "C",
    "explanation": "Recurrent Neural Networks (RNNs) are designed to process sequential data due to their internal memory.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 12,
    "question": "What is a 'neuron' in a neural network conceptually similar to?",
    "options": {
      "A": "A hard drive",
      "B": "A biological neuron",
      "C": "A database",
      "D": "A printer"
    },
    "answer": "B",
    "explanation": "Artificial neurons are inspired by the structure and function of biological neurons in the brain.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 13,
    "question": "What is 'backpropagation' primarily used for in neural networks?",
    "options": {
      "A": "Forward pass computation",
      "B": "Weight initialization",
      "C": "Updating model weights",
      "D": "Data preprocessing"
    },
    "answer": "C",
    "explanation": "Backpropagation is the algorithm that computes gradients and updates weights to minimize the loss.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 14,
    "question": "Which layer typically comes after a convolutional layer in a CNN?",
    "options": {
      "A": "Input Layer",
      "B": "Output Layer",
      "C": "Pooling Layer",
      "D": "Recurrent Layer"
    },
    "answer": "C",
    "explanation": "Pooling layers often follow convolutional layers to reduce spatial dimensions and extract dominant features.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 15,
    "question": "What is a 'hyperparameter' in deep learning?",
    "options": {
      "A": "A parameter learned by the model",
      "B": "A configuration setting external to the model, set before training",
      "C": "The output of an activation function",
      "D": "The loss value at the end of training"
    },
    "answer": "B",
    "explanation": "Hyperparameters (e.g., learning rate, number of layers) are set manually before training, unlike model parameters (weights, biases) which are learned.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 16,
    "question": "What is the function of the 'softmax' activation in the output layer for multi-class classification?",
    "options": {
      "A": "To output a single binary decision",
      "B": "To ensure outputs sum to one, representing probabilities",
      "C": "To make all outputs negative",
      "D": "To apply a linear transformation"
    },
    "answer": "B",
    "explanation": "Softmax converts a vector of numbers into a probability distribution where all values are between 0 and 1 and sum to 1.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 17,
    "question": "Which term describes the process of feeding input data through the neural network to get an output?",
    "options": {
      "A": "Backpropagation",
      "B": "Gradient Descent",
      "C": "Forward Propagation",
      "D": "Optimization"
    },
    "answer": "C",
    "explanation": "Forward propagation (or forward pass) is the process of calculating the output of the network given an input.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 18,
    "question": "What is a 'batch' in the context of deep learning training?",
    "options": {
      "A": "The entire dataset",
      "B": "A small subset of the training data used in one iteration",
      "C": "The final output of the model",
      "D": "The learning rate"
    },
    "answer": "B",
    "explanation": "Training data is often divided into smaller batches to make the training process more efficient and stable.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 19,
    "question": "Which of these concepts is related to preventing overfitting?",
    "options": {
      "A": "Increasing model complexity",
      "B": "Using a very small dataset",
      "C": "Dropout",
      "D": "Increasing the number of epochs indefinitely"
    },
    "answer": "C",
    "explanation": "Dropout is a regularization technique that randomly deactivates neurons during training to prevent co-adaptation.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 20,
    "question": "What is a 'fully connected layer' also known as?",
    "options": {
      "A": "Convolutional Layer",
      "B": "Dense Layer",
      "C": "Pooling Layer",
      "D": "Recurrent Layer"
    },
    "answer": "B",
    "explanation": "In a dense (fully connected) layer, every neuron in the layer is connected to every neuron in the previous layer.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 21,
    "question": "What does 'epoch' refer to in deep learning training?",
    "options": {
      "A": "One forward pass through the network",
      "B": "One backward pass through the network",
      "C": "One complete pass of the entire training dataset through the network",
      "D": "The number of hidden layers"
    },
    "answer": "C",
    "explanation": "An epoch represents one full cycle of feeding the entire training data through the neural network, both forward and backward.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 22,
    "question": "Which type of layer extracts features from local regions of an image?",
    "options": {
      "A": "Dense layer",
      "B": "Input layer",
      "C": "Convolutional layer",
      "D": "Output layer"
    },
    "answer": "C",
    "explanation": "Convolutional layers use filters to detect patterns and features in specific regions of an image.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 23,
    "question": "What is the primary benefit of using a GPU for deep learning?",
    "options": {
      "A": "Lower memory consumption",
      "B": "Faster sequential processing",
      "C": "Parallel processing capabilities for matrix operations",
      "D": "Easier debugging"
    },
    "answer": "C",
    "explanation": "GPUs are highly optimized for parallel computation, which is essential for the large matrix multiplications in neural networks.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 24,
    "question": "Which of these is a common problem in training very deep networks?",
    "options": {
      "A": "Exploding features",
      "B": "Vanishing/Exploding Gradients",
      "C": "Data overflow",
      "D": "Underfitting input"
    },
    "answer": "B",
    "explanation": "Vanishing and exploding gradients are common challenges in training deep networks, making it difficult for early layers to learn.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 25,
    "question": "What is the goal of an 'autoencoder'?",
    "options": {
      "A": "To classify data into different classes",
      "B": "To generate realistic images",
      "C": "To learn a compressed, useful representation of input data",
      "D": "To predict future values in a time series"
    },
    "answer": "C",
    "explanation": "Autoencoders are unsupervised learning models that learn efficient data codings by reconstructing their inputs.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 26,
    "question": "What is the purpose of 'padding' in CNNs?",
    "options": {
      "A": "To increase the image resolution",
      "B": "To ensure the output feature map size matches the input size",
      "C": "To reduce the number of parameters",
      "D": "To skip certain pixels"
    },
    "answer": "B",
    "explanation": "Padding adds zeros around the input image's border, preventing the loss of information at the edges and controlling the output size.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 27,
    "question": "Which type of layer in RNNs helps in remembering long-term dependencies?",
    "options": {
      "A": "Convolutional layer",
      "B": "Dense layer",
      "C": "LSTM cell",
      "D": "Pooling layer"
    },
    "answer": "C",
    "explanation": "Long Short-Term Memory (LSTM) cells are a type of recurrent unit designed to capture long-term dependencies more effectively than simple RNNs.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 28,
    "question": "What does 'GAN' stand for?",
    "options": {
      "A": "General AI Network",
      "B": "Generative Adversarial Network",
      "C": "Global Attention Network",
      "D": "Gradient Activation Network"
    },
    "answer": "B",
    "explanation": "GANs are a class of AI algorithms used in unsupervised machine learning, implemented by a system of two neural networks competing against each other.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 29,
    "question": "Which task is a common application of deep learning?",
    "options": {
      "A": "Simple arithmetic calculations",
      "B": "Image classification",
      "C": "Sorting a small list of numbers",
      "D": "Database querying"
    },
    "answer": "B",
    "explanation": "Deep learning excels at complex tasks like image classification, natural language processing, and speech recognition.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 30,
    "question": "What is the purpose of a 'learning rate' in an optimizer?",
    "options": {
      "A": "The speed of forward propagation",
      "B": "The size of the weight updates during optimization",
      "C": "The number of layers in the network",
      "D": "The rate at which data is loaded"
    },
    "answer": "B",
    "explanation": "The learning rate determines the step size at which an optimizer adjusts the model's weights during training.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 31,
    "question": "Which of these is NOT a type of neural network?",
    "options": {
      "A": "Feedforward Neural Network",
      "B": "Decision Tree Network",
      "C": "Recurrent Neural Network",
      "D": "Convolutional Neural Network"
    },
    "answer": "B",
    "explanation": "Decision Trees are a traditional machine learning algorithm, not a type of neural network.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 32,
    "question": "What is the input to the first layer of a neural network?",
    "options": {
      "A": "Hidden features",
      "B": "Raw data features",
      "C": "Weights and biases",
      "D": "Loss function output"
    },
    "answer": "B",
    "explanation": "The first layer (input layer) directly receives the raw features of the data.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 33,
    "question": "What does 'fine-tuning' refer to in transfer learning?",
    "options": {
      "A": "Training a model from scratch",
      "B": "Adjusting the architecture of a pre-trained model",
      "C": "Retraining all layers of a pre-trained model on a new dataset",
      "D": "Training only the last layers of a pre-trained model on a new dataset"
    },
    "answer": "D",
    "explanation": "Fine-tuning typically involves taking a pre-trained model and retraining some or all of its layers on a new, specific dataset.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 34,
    "question": "What is the purpose of 'Batch Normalization'?",
    "options": {
      "A": "To make the input data normally distributed",
      "B": "To normalize the outputs of hidden layers, stabilizing training",
      "C": "To reduce the number of parameters",
      "D": "To prevent vanishing gradients by making activations non-linear"
    },
    "answer": "B",
    "explanation": "Batch Normalization normalizes the inputs to layers, helping to speed up training and provide regularization.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 35,
    "question": "Which of these is a popular dataset for image classification tasks in deep learning?",
    "options": {
      "A": "Iris dataset",
      "B": "MNIST",
      "C": "Boston Housing",
      "D": "Titanic dataset"
    },
    "answer": "B",
    "explanation": "MNIST is a well-known dataset of handwritten digits, widely used for benchmarking image classification models.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 36,
    "question": "What is the primary role of an 'encoder' in an autoencoder?",
    "options": {
      "A": "To reconstruct the input",
      "B": "To compress the input data into a lower-dimensional representation",
      "C": "To classify the input data",
      "D": "To generate new data"
    },
    "answer": "B",
    "explanation": "The encoder part of an autoencoder learns to map the input data into a latent, compressed representation.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 37,
    "question": "Which deep learning concept is associated with 'feature maps'?",
    "options": {
      "A": "Recurrent Neural Networks",
      "B": "Generative Adversarial Networks",
      "C": "Convolutional Neural Networks",
      "D": "Reinforcement Learning"
    },
    "answer": "C",
    "explanation": "Feature maps are the outputs of convolutional layers, representing detected features in the input.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 38,
    "question": "What is 'Tensor' in TensorFlow?",
    "options": {
      "A": "A type of neural network layer",
      "B": "A mathematical object representing multi-dimensional arrays",
      "C": "An optimization algorithm",
      "D": "A specific type of loss function"
    },
    "answer": "B",
    "explanation": "In TensorFlow, data is represented as tensors, which are multi-dimensional arrays.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 39,
    "question": "Which component in a GAN is responsible for generating new data samples?",
    "options": {
      "A": "Discriminator",
      "B": "Generator",
      "C": "Optimizer",
      "D": "Loss function"
    },
    "answer": "B",
    "explanation": "The Generator network in a GAN learns to produce new data samples that resemble the training data.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 40,
    "question": "What is the primary benefit of using deep learning over traditional machine learning for very large datasets?",
    "options": {
      "A": "Deep learning models are always simpler to understand",
      "B": "Deep learning automatically learns hierarchical features, scaling better with data size",
      "C": "Traditional ML models cannot handle large datasets",
      "D": "Deep learning requires less computational power for large datasets"
    },
    "answer": "B",
    "explanation": "Deep learning's ability to learn complex feature hierarchies makes it very effective with large amounts of data, often outperforming traditional ML.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 41,
    "question": "What is the role of a 'stride' in a convolutional layer?",
    "options": {
      "A": "It defines the depth of the filter",
      "B": "It determines how many pixels the filter moves at each step",
      "C": "It adds zeros around the input image",
      "D": "It selects the maximum value in a region"
    },
    "answer": "B",
    "explanation": "Stride defines the step size of the convolutional filter as it moves across the input image.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 42,
    "question": "Which term refers to the process of adjusting a neural network's weights and biases?",
    "options": {
      "A": "Inference",
      "B": "Prediction",
      "C": "Training",
      "D": "Validation"
    },
    "answer": "C",
    "explanation": "Training is the process where a neural network learns from data by adjusting its internal parameters.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 43,
    "question": "What does a 'dense' layer compute?",
    "options": {
      "A": "Convolutional operations",
      "B": "Matrix multiplication of its inputs with weights, plus a bias",
      "C": "Pooling operations",
      "D": "Recurrent computations"
    },
    "answer": "B",
    "explanation": "A dense layer performs a linear transformation on its input (weights * input + bias) followed by an activation function.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 44,
    "question": "What is 'data augmentation' used for in deep learning?",
    "options": {
      "A": "To reduce the dataset size",
      "B": "To create more training data by applying transformations (e.g., rotations, flips) to existing data",
      "C": "To normalize data distribution",
      "D": "To remove outliers from the dataset"
    },
    "answer": "B",
    "explanation": "Data augmentation generates new training samples from existing ones to increase dataset size and improve model robustness.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 45,
    "question": "Which type of problem does 'regression' address in deep learning?",
    "options": {
      "A": "Predicting categorical labels",
      "B": "Predicting continuous numerical values",
      "C": "Grouping similar data points",
      "D": "Generating new data"
    },
    "answer": "B",
    "explanation": "Regression models predict a continuous output, such as house prices or temperature.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 46,
    "question": "What is the purpose of the 'output layer' in a neural network?",
    "options": {
      "A": "To perform feature extraction",
      "B": "To make the final prediction or decision of the network",
      "C": "To normalize input data",
      "D": "To introduce non-linearity"
    },
    "answer": "B",
    "explanation": "The output layer produces the final result of the neural network, often transformed by an appropriate activation function.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 47,
    "question": "What is a 'kernel' in a convolutional layer also known as?",
    "options": {
      "A": "A neuron",
      "B": "A feature map",
      "C": "A filter",
      "D": "A bias"
    },
    "answer": "C",
    "explanation": "The kernel is a small matrix of weights that slides over the input to detect specific features, often called a filter.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 48,
    "question": "Which of these is a common strategy to prevent underfitting?",
    "options": {
      "A": "Reducing model complexity",
      "B": "Increasing regularization",
      "C": "Increasing model complexity (e.g., adding more layers/neurons)",
      "D": "Decreasing the number of training epochs"
    },
    "answer": "C",
    "explanation": "Underfitting occurs when a model is too simple to capture the underlying patterns; increasing complexity can help.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 49,
    "question": "What is the primary output of a 'pooling' operation?",
    "options": {
      "A": "A larger feature map",
      "B": "A flattened vector",
      "C": "A downsampled feature map",
      "D": "A probability distribution"
    },
    "answer": "C",
    "explanation": "Pooling layers reduce the spatial dimensions (width and height) of the input feature map.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 50,
    "question": "What is 'transfer learning' in deep learning?",
    "options": {
      "A": "Training a model on a different type of hardware",
      "B": "Applying a model trained on one task to a different but related task",
      "C": "Transferring data between different neural networks",
      "D": "Learning new knowledge from scratch without prior data"
    },
    "answer": "B",
    "explanation": "Transfer learning reuses knowledge (pre-trained weights) from a model trained on a large dataset for a new, often smaller, related task.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 51,
    "question": "What does the 'bias' term represent in a neuron?",
    "options": {
      "A": "The input to the neuron",
      "B": "The weight of the connection",
      "C": "An additional constant added to the weighted sum of inputs before activation",
      "D": "The output of the activation function"
    },
    "answer": "C",
    "explanation": "The bias term allows the activation function to be shifted, providing more flexibility for the model to fit the data.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 52,
    "question": "Which of these is a common deep learning library developed by Google?",
    "options": {
      "A": "PyTorch",
      "B": "Keras",
      "C": "TensorFlow",
      "D": "Caffe"
    },
    "answer": "C",
    "explanation": "TensorFlow is an open-source machine learning framework developed by Google.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 53,
    "question": "What is a 'deep' neural network characterized by?",
    "options": {
      "A": "Having only an input and output layer",
      "B": "Having many hidden layers",
      "C": "Being very large in terms of training data",
      "D": "Using only linear activation functions"
    },
    "answer": "B",
    "explanation": "A 'deep' network implies a network with multiple hidden layers, allowing it to learn complex hierarchies of features.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 54,
    "question": "Which type of problem is 'classification' in deep learning?",
    "options": {
      "A": "Predicting continuous values",
      "B": "Assigning data points to discrete categories or classes",
      "C": "Generating new data samples",
      "D": "Reducing the dimensionality of data"
    },
    "answer": "B",
    "explanation": "Classification involves categorizing input data into one of several predefined classes (e.g., dog vs. cat).",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 55,
    "question": "What is the primary output of a 'flatten' layer in a CNN?",
    "options": {
      "A": "A 2D matrix",
      "B": "A 3D tensor",
      "C": "A 1D vector",
      "D": "A single scalar value"
    },
    "answer": "C",
    "explanation": "A flatten layer converts multi-dimensional feature maps into a single long vector, typically before passing to dense layers.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 56,
    "question": "What is the purpose of 'validation data' during deep learning training?",
    "options": {
      "A": "To train the model on",
      "B": "To test the final model performance on unseen data",
      "C": "To tune hyperparameters and monitor for overfitting during training",
      "D": "To generate new data"
    },
    "answer": "C",
    "explanation": "Validation data is used to evaluate the model's performance on unseen data during training and helps in hyperparameter tuning and early stopping.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 57,
    "question": "Which of these optimizers uses only the current gradient to update weights?",
    "options": {
      "A": "Adam",
      "B": "RMSprop",
      "C": "SGD (Stochastic Gradient Descent)",
      "D": "Adagrad"
    },
    "answer": "C",
    "explanation": "Basic SGD updates weights based solely on the current batch's gradient, unlike adaptive optimizers.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 58,
    "question": "What is the purpose of 'weight initialization' in neural networks?",
    "options": {
      "A": "To reset weights after each epoch",
      "B": "To assign initial values to the network's weights before training begins",
      "C": "To set the learning rate",
      "D": "To define the network architecture"
    },
    "answer": "B",
    "explanation": "Good weight initialization is crucial for stable training and avoiding issues like vanishing/exploding gradients early on.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 59,
    "question": "Which concept allows a CNN to learn local patterns that are useful across different parts of an image?",
    "options": {
      "A": "Recurrence",
      "B": "Shared Weights (Parameter Sharing)",
      "C": "Long-term memory",
      "D": "Gradient clipping"
    },
    "answer": "B",
    "explanation": "Convolutional filters (kernels) use the same weights across different spatial locations, enabling them to detect patterns universally.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 60,
    "question": "What is 'Dropout' primarily designed to achieve?",
    "options": {
      "A": "Reduce memory usage",
      "B": "Speed up computation",
      "C": "Prevent overfitting",
      "D": "Increase model accuracy on the training set"
    },
    "answer": "C",
    "explanation": "Dropout randomly deactivates neurons during training, forcing the network to learn more robust features and preventing co-adaptation.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 61,
    "question": "What is 'Adam' in deep learning?",
    "options": {
      "A": "An activation function",
      "B": "A type of recurrent neural network",
      "C": "An optimization algorithm",
      "D": "A regularization technique"
    },
    "answer": "C",
    "explanation": "Adam (Adaptive Moment Estimation) is a popular optimization algorithm known for its efficiency.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 62,
    "question": "Which of these tasks is often performed by an Autoencoder?",
    "options": {
      "A": "Speech recognition",
      "B": "Image classification",
      "C": "Dimensionality reduction",
      "D": "Machine translation"
    },
    "answer": "C",
    "explanation": "Autoencoders learn a compressed representation (encoding) of the input data, effectively reducing its dimensionality.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 63,
    "question": "What does 'RNN' stand for?",
    "options": {
      "A": "Randomly Normalized Network",
      "B": "Recurrent Neural Network",
      "C": "Rectified Neuron Network",
      "D": "Reinforcement Neural Network"
    },
    "answer": "B",
    "explanation": "RNNs are a class of neural networks where connections between nodes form a directed graph along a temporal sequence.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 64,
    "question": "Which part of a neural network is responsible for introducing non-linearity?",
    "options": {
      "A": "Weights",
      "B": "Biases",
      "C": "Activation Function",
      "D": "Input Layer"
    },
    "answer": "C",
    "explanation": "Activation functions introduce non-linearity, allowing neural networks to learn complex, non-linear relationships.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 65,
    "question": "What is the purpose of a 'seed' when generating random numbers in deep learning?",
    "options": {
      "A": "To make the random numbers truly random",
      "B": "To ensure reproducibility of results by fixing the starting point for randomness",
      "C": "To speed up random number generation",
      "D": "To prevent random numbers from being too large"
    },
    "answer": "B",
    "explanation": "Setting a seed for random number generators ensures that the 'random' operations (like weight initialization or shuffling) produce the same sequence of numbers each time, making experiments reproducible.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 66,
    "question": "Which term describes the process of converting continuous output probabilities into discrete class labels?",
    "options": {
      "A": "Regression",
      "B": "Normalization",
      "C": "Thresholding",
      "D": "Embedding"
    },
    "answer": "C",
    "explanation": "Thresholding (e.g., for binary classification, values > 0.5 become class 1) is used to convert probabilities into distinct classes.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 67,
    "question": "What is 'Dropout rate' in the context of dropout regularization?",
    "options": {
      "A": "The number of neurons in a layer",
      "B": "The percentage of neurons randomly set to zero during training",
      "C": "The rate at which the learning rate decreases",
      "D": "The number of training samples dropped from each batch"
    },
    "answer": "B",
    "explanation": "The dropout rate specifies the probability that any given neuron's output will be set to zero during training.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 68,
    "question": "In a CNN, what does a 'filter' learn to detect?",
    "options": {
      "A": "Overall image brightness",
      "B": "Specific patterns or features (e.g., edges, textures)",
      "C": "The average color of the image",
      "D": "The position of the object in the image"
    },
    "answer": "B",
    "explanation": "Each filter in a convolutional layer learns to identify a particular feature (like a vertical edge or a specific texture) in the input.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 69,
    "question": "What is a 'TensorBoard' primarily used for?",
    "options": {
      "A": "Writing deep learning code",
      "B": "Monitoring and visualizing deep learning model training",
      "C": "Deploying deep learning models",
      "D": "Collecting training data"
    },
    "answer": "B",
    "explanation": "TensorBoard is a visualization tool provided with TensorFlow that helps in understanding, debugging, and optimizing neural networks.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 70,
    "question": "Which type of layer is NOT typically found in a standard Feedforward Neural Network (FNN)?",
    "options": {
      "A": "Input Layer",
      "B": "Hidden Layer",
      "C": "Convolutional Layer",
      "D": "Output Layer"
    },
    "answer": "C",
    "explanation": "Feedforward neural networks consist of input, hidden, and output layers. Convolutional layers are specific to CNNs.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 71,
    "question": "What is the primary function of the 'Decoder' in an autoencoder?",
    "options": {
      "A": "To compress data",
      "B": "To reconstruct the original input from the compressed representation",
      "C": "To classify data",
      "D": "To extract features"
    },
    "answer": "B",
    "explanation": "The decoder takes the compressed representation (latent code) and attempts to reconstruct the original input.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 72,
    "question": "Which loss function is commonly used for binary classification problems in deep learning?",
    "options": {
      "A": "Mean Squared Error (MSE)",
      "B": "Categorical Cross-Entropy",
      "C": "Binary Cross-Entropy",
      "D": "Huber Loss"
    },
    "answer": "C",
    "explanation": "Binary Cross-Entropy loss is specifically designed for binary classification tasks (two classes).",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 73,
    "question": "What is 'GPU' in the context of deep learning?",
    "options": {
      "A": "General Processing Unit",
      "B": "Graphics Processing Unit",
      "C": "Gradient Processing Unit",
      "D": "Global Parameter Unit"
    },
    "answer": "B",
    "explanation": "GPUs are specialized electronic circuits designed to rapidly manipulate and alter memory to accelerate the creation of images, crucial for deep learning computations.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 74,
    "question": "What is 'Model capacity' in deep learning?",
    "options": {
      "A": "The amount of memory the model uses",
      "B": "The size of the dataset the model can handle",
      "C": "The ability of a model to learn complex functions (its complexity)",
      "D": "The speed at which the model makes predictions"
    },
    "answer": "C",
    "explanation": "Model capacity refers to a model's ability to fit various functions, often related to the number of parameters and layers.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 75,
    "question": "Which of these describes a 'supervised learning' task in deep learning?",
    "options": {
      "A": "Clustering data without labels",
      "B": "Training a model with labeled data to predict outputs",
      "C": "Generating new data samples",
      "D": "Reducing data dimensionality without target variables"
    },
    "answer": "B",
    "explanation": "Supervised learning involves learning a mapping from input features to output labels from a dataset of labeled examples.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 76,
    "question": "What is a 'Dense Layer' primarily used for in a CNN after convolutional and pooling layers?",
    "options": {
      "A": "Further feature extraction",
      "B": "Downsampling feature maps",
      "C": "Making final classifications or predictions",
      "D": "Handling sequential data"
    },
    "answer": "C",
    "explanation": "After feature extraction and reduction by convolutional and pooling layers, dense layers are often used for the final classification or regression based on the learned features.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 77,
    "question": "Which of the following is an advantage of using ReLU over Sigmoid in hidden layers?",
    "options": {
      "A": "ReLU outputs probabilities directly",
      "B": "ReLU is less prone to the vanishing gradient problem for positive inputs",
      "C": "ReLU is always differentiable",
      "D": "ReLU is computationally more intensive"
    },
    "answer": "B",
    "explanation": "ReLU's constant gradient for positive inputs helps mitigate vanishing gradients, unlike Sigmoid, which saturates.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 78,
    "question": "What is the role of a 'padding' operation in a Convolutional Neural Network?",
    "options": {
      "A": "To increase the computational cost",
      "B": "To ensure that the spatial dimensions of the output feature map are larger than the input",
      "C": "To add extra zeros around the input image, preserving border information",
      "D": "To remove irrelevant features from the image"
    },
    "answer": "C",
    "explanation": "Padding adds zeros around the input boundaries, which helps in retaining information at the edges and controlling the output size of convolutional layers.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 79,
    "question": "What is 'Keras' in the context of deep learning?",
    "options": {
      "A": "A type of neural network architecture",
      "B": "A high-level API for building and training deep learning models",
      "C": "A specific optimization algorithm",
      "D": "A dataset for natural language processing"
    },
    "answer": "B",
    "explanation": "Keras is a user-friendly neural network API written in Python, capable of running on top of TensorFlow, CNTK, or Theano.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 80,
    "question": "What is the main idea behind 'Ensemble learning' in deep learning?",
    "options": {
      "A": "Training a single, very large model",
      "B": "Combining predictions from multiple models to improve overall performance",
      "C": "Using only one type of activation function",
      "D": "Reducing the number of hidden layers"
    },
    "answer": "B",
    "explanation": "Ensemble methods train multiple models and combine their predictions, often leading to more robust and accurate results than a single model.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 81,
    "question": "Which of these is a popular pre-trained model for image recognition?",
    "options": {
      "A": "GPT-3",
      "B": "BERT",
      "C": "ResNet",
      "D": "Word2Vec"
    },
    "answer": "C",
    "explanation": "ResNet (Residual Network) is a widely used CNN architecture known for its performance in image classification.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 82,
    "question": "What does 'NLP' stand for in the context of deep learning applications?",
    "options": {
      "A": "Neural Logic Programming",
      "B": "Natural Language Processing",
      "C": "Network Layer Protocol",
      "D": "Non-Linear Perception"
    },
    "answer": "B",
    "explanation": "NLP is a field of AI focused on enabling computers to understand, interpret, and generate human language.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 83,
    "question": "Which type of layer processes input data one step at a time, maintaining an internal state?",
    "options": {
      "A": "Dense Layer",
      "B": "Convolutional Layer",
      "C": "Recurrent Layer",
      "D": "Flatten Layer"
    },
    "answer": "C",
    "explanation": "Recurrent layers (like in RNNs, LSTMs, GRUs) process sequences sequentially, with their output at each step depending on the current input and the previous hidden state.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 84,
    "question": "What is the 'output shape' of a neural network layer?",
    "options": {
      "A": "The number of training epochs",
      "B": "The dimensions of the tensor produced by the layer",
      "C": "The type of activation function used",
      "D": "The number of parameters in the layer"
    },
    "answer": "B",
    "explanation": "Output shape refers to the dimensions (e.g., batch size, height, width, channels) of the data tensor that a layer outputs.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 85,
    "question": "What is 'early stopping' used for in deep learning?",
    "options": {
      "A": "To stop training immediately after the first epoch",
      "B": "To halt training when performance on a validation set starts to degrade",
      "C": "To stop the model from learning completely",
      "D": "To pre-train a model on a small dataset"
    },
    "answer": "B",
    "explanation": "Early stopping is a regularization technique that stops training when the model's performance on a validation set stops improving, preventing overfitting.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 86,
    "question": "Which of these is a common metric for evaluating regression models in deep learning?",
    "options": {
      "A": "Accuracy",
      "B": "Precision",
      "C": "Mean Squared Error (MSE)",
      "D": "F1-score"
    },
    "answer": "C",
    "explanation": "MSE is a widely used metric for regression problems, measuring the average squared difference between predicted and actual values.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 87,
    "question": "What is the primary characteristic of a 'sequential model' in Keras?",
    "options": {
      "A": "It can have multiple inputs and outputs",
      "B": "Layers are stacked linearly, one after the other",
      "C": "It is used only for recurrent neural networks",
      "D": "It requires manual weight initialization"
    },
    "answer": "B",
    "explanation": "The Keras Sequential API allows building models layer-by-layer in a linear stack, making it straightforward for simple architectures.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 88,
    "question": "What is a 'gradient' in the context of deep learning?",
    "options": {
      "A": "The output of an activation function",
      "B": "The derivative of the loss function with respect to the model's weights",
      "C": "A type of layer in a neural network",
      "D": "A measure of model complexity"
    },
    "answer": "B",
    "explanation": "Gradients indicate the direction and magnitude of the steepest ascent (or descent for loss minimization) in the loss landscape.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 89,
    "question": "What is the main concept behind 'Representation Learning' in deep learning?",
    "options": {
      "A": "Manually creating features for a model",
      "B": "Learning meaningful data representations automatically from raw data",
      "C": "Visualizing model decisions",
      "D": "Storing data efficiently in memory"
    },
    "answer": "B",
    "explanation": "Deep learning models excel at representation learning, where they learn increasingly abstract and useful features from raw input data.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 90,
    "question": "Which type of layer connects all its neurons to all neurons in the preceding layer?",
    "options": {
      "A": "Pooling Layer",
      "B": "Convolutional Layer",
      "C": "Dense Layer",
      "D": "Recurrent Layer"
    },
    "answer": "C",
    "explanation": "A dense (or fully connected) layer has connections between every neuron in its layer and every neuron in the previous layer.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 91,
    "question": "What is the term for the process of converting textual data into numerical format for deep learning?",
    "options": {
      "A": "Image encoding",
      "B": "Tokenization and Embedding",
      "C": "Data normalization",
      "D": "Feature scaling"
    },
    "answer": "B",
    "explanation": "Text is typically tokenized into words or subwords, and then converted into numerical vector representations (embeddings) that deep learning models can process.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 92,
    "question": "Which of these is a common application of Recurrent Neural Networks (RNNs)?",
    "options": {
      "A": "Image classification",
      "B": "Speech recognition",
      "C": "Object detection",
      "D": "Generating static images"
    },
    "answer": "B",
    "explanation": "RNNs are well-suited for tasks involving sequential data like speech, where the order of information matters.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 93,
    "question": "What does 'unsupervised learning' typically involve in deep learning?",
    "options": {
      "A": "Training with labeled data to predict outputs",
      "B": "Learning patterns from unlabeled data",
      "C": "Using reinforcement signals to learn optimal actions",
      "D": "Transferring knowledge from a pre-trained model"
    },
    "answer": "B",
    "explanation": "Unsupervised learning focuses on finding hidden patterns or structures in data without explicit labels, such as in autoencoders or GANs.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 94,
    "question": "What is 'Dropout' a form of?",
    "options": {
      "A": "Data augmentation",
      "B": "Normalization",
      "C": "Regularization",
      "D": "Optimization"
    },
    "answer": "C",
    "explanation": "Dropout is a powerful regularization technique that helps prevent overfitting in neural networks.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 95,
    "question": "Which type of layer is best for extracting spatial hierarchies of features from images?",
    "options": {
      "A": "Dense",
      "B": "Recurrent",
      "C": "Convolutional",
      "D": "Flatten"
    },
    "answer": "C",
    "explanation": "Convolutional layers with hierarchical stacking (multiple conv layers) are designed to learn spatial features at different levels of abstraction.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 96,
    "question": "What does 'model checkpointing' mean?",
    "options": {
      "A": "Checking the model's performance manually",
      "B": "Saving the model's weights at intervals during training",
      "C": "Deleting unnecessary model files",
      "D": "Restarting training from scratch"
    },
    "answer": "B",
    "explanation": "Model checkpointing involves saving the state of a model (its weights and possibly optimizer state) periodically during training, allowing for recovery or selection of the best model.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 97,
    "question": "Which of these is a widely used dataset for natural language processing tasks?",
    "options": {
      "A": "ImageNet",
      "B": "IMDb movie reviews dataset",
      "C": "CIFAR-10",
      "D": "Fashion MNIST"
    },
    "answer": "B",
    "explanation": "The IMDb dataset, consisting of movie reviews, is a common benchmark for sentiment analysis and other NLP tasks.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 98,
    "question": "What is the goal of 'gradient descent' in deep learning?",
    "options": {
      "A": "To increase the loss function",
      "B": "To find the minimum of the loss function by iteratively moving in the direction of steepest descent",
      "C": "To randomly change weights",
      "D": "To only update the bias terms"
    },
    "answer": "B",
    "explanation": "Gradient descent is an iterative optimization algorithm used to find the local minimum of a function.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 99,
    "question": "What does 'fine-tuning' typically imply about the initial weights of a model?",
    "options": {
      "A": "They are randomly initialized",
      "B": "They are fixed and never changed",
      "C": "They are pre-trained on a larger, related dataset",
      "D": "They are set to zero"
    },
    "answer": "C",
    "explanation": "Fine-tuning starts with a model that has already learned general features from a large dataset, and then adapts those features to a specific new task.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 100,
    "question": "Which of the following is an example of an 'end-to-end' deep learning system?",
    "options": {
      "A": "A system where features are manually extracted, then fed into a simple classifier",
      "B": "A system that directly learns a mapping from raw input data to the desired output",
      "C": "A system that requires separate models for each sub-task",
      "D": "A system where human intervention is required at every step"
    },
    "answer": "B",
    "explanation": "End-to-end deep learning systems take raw data as input and produce the final output, learning all intermediate representations automatically.",
    "topic": "Deep Learning",
    "difficulty": "Easy"
  },
  {
    "id": 101,
    "question": "What is the primary difference between a simple RNN and an LSTM?",
    "options": {
      "A": "Simple RNNs have more layers than LSTMs.",
      "B": "LSTMs use convolutional filters while RNNs do not.",
      "C": "LSTMs have internal 'gates' that allow them to selectively remember or forget information, addressing vanishing/exploding gradients over long sequences.",
      "D": "Simple RNNs are used for images, LSTMs for text."
    },
    "answer": "C",
    "explanation": "LSTM cells contain input, output, and forget gates that enable them to capture long-range dependencies more effectively than simple RNNs.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 102,
    "question": "When might 'weight decay' (L2 regularization) be preferred over 'dropout'?",
    "options": {
      "A": "When the model is underfitting.",
      "B": "When training small models or in situations where interpretability is crucial.",
      "C": "When vanishing gradients are a severe issue.",
      "D": "When computational resources are extremely limited."
    },
    "answer": "B",
    "explanation": "Weight decay is a continuous regularization that shrinks weights, offering more stability than dropout for smaller models or when randomness from dropout is undesirable. Dropout can be more effective for very deep or wide networks.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 103,
    "question": "Explain the concept of 'receptive field' in a Convolutional Neural Network.",
    "options": {
      "A": "The total number of neurons in a layer.",
      "B": "The area of the input image that a neuron in a subsequent layer 'sees' or is influenced by.",
      "C": "The size of the output feature map.",
      "D": "The number of filters applied in a convolutional layer."
    },
    "answer": "B",
    "explanation": "The receptive field of a neuron in a CNN is the region in the input space that affects that neuron's activation. It grows larger in deeper layers.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 104,
    "question": "What is the primary motivation for using residual connections (skip connections) in architectures like ResNet?",
    "options": {
      "A": "To replace all activation functions with linear ones.",
      "B": "To allow gradients to flow directly through deeper layers, mitigating vanishing gradients and enabling training of much deeper networks.",
      "C": "To drastically reduce the number of parameters.",
      "D": "To force the network to learn only linear transformations."
    },
    "answer": "B",
    "explanation": "Residual connections provide an alternative path for gradients, helping to train very deep networks by addressing the degradation problem where accuracy saturates and then degrades with increasing depth.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 105,
    "question": "How does 'Batch Normalization' help in training deep neural networks?",
    "options": {
      "A": "By completely eliminating the need for activation functions.",
      "B": "By normalizing the input to each mini-batch, it reduces internal covariate shift, allowing higher learning rates and faster training.",
      "C": "By always setting neuron activations to zero for normalization.",
      "D": "By directly setting all weights to specific small values."
    },
    "answer": "B",
    "explanation": "Batch Normalization normalizes the activations of intermediate layers, stabilizing the training process, reducing sensitivity to initialization, and allowing for higher learning rates.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 106,
    "question": "What is the 'exploding gradient' problem and how can it be mitigated?",
    "options": {
      "A": "Gradients become too small; mitigated by using ReLU.",
      "B": "Gradients become too large, leading to unstable training; mitigated by gradient clipping.",
      "C": "Model weights become zero; mitigated by increasing learning rate.",
      "D": "Loss function explodes to infinity; mitigated by adding more layers."
    },
    "answer": "B",
    "explanation": "Exploding gradients occur when gradients accumulate during backpropagation, leading to large weight updates. Gradient clipping limits the maximum value of gradients.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 107,
    "question": "In a GAN, what is the primary objective of the 'Discriminator' network during training?",
    "options": {
      "A": "To generate realistic new data samples.",
      "B": "To distinguish between real data samples and fake (generated) data samples.",
      "C": "To reconstruct the input image from a latent code.",
      "D": "To optimize the weights of the Generator."
    },
    "answer": "B",
    "explanation": "The Discriminator's goal is to become an expert at telling real data apart from synthetic data generated by the Generator.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 108,
    "question": "Why is 'categorical cross-entropy' often used as a loss function for multi-class classification?",
    "options": {
      "A": "It works best for regression tasks.",
      "B": "It specifically handles binary outputs (0 or 1).",
      "C": "It measures the difference between two probability distributions, which is ideal when the model outputs probabilities for multiple classes and the true labels are one-hot encoded.",
      "D": "It's computationally less expensive than MSE."
    },
    "answer": "C",
    "explanation": "Categorical cross-entropy (or Sparse Categorical Cross-Entropy) is suitable for multi-class classification problems where the output layer uses softmax and the true labels are categorical.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 109,
    "question": "What is the concept of 'semantic segmentation' in computer vision?",
    "options": {
      "A": "Identifying bounding boxes around objects.",
      "B": "Classifying an entire image into a single category.",
      "C": "Assigning a class label to every pixel in an image.",
      "D": "Generating new, realistic images."
    },
    "answer": "C",
    "explanation": "Semantic segmentation involves partitioning an image into meaningful regions and assigning a class label to each pixel.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 110,
    "question": "When might a 'U-Net' architecture be preferred in deep learning?",
    "options": {
      "A": "For simple image classification tasks.",
      "B": "For sequence generation tasks like text translation.",
      "C": "For image segmentation tasks, especially in medical imaging, due to its ability to capture both context and precise localization.",
      "D": "For time series forecasting."
    },
    "answer": "C",
    "explanation": "U-Net is a convolutional network architecture designed for biomedical image segmentation, known for its U-shaped encoder-decoder structure and skip connections.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 111,
    "question": "Describe the 'attention mechanism' in neural networks, particularly in Transformers.",
    "options": {
      "A": "It helps the model to focus on all parts of the input equally.",
      "B": "It allows the model to dynamically weight the importance of different parts of the input sequence when making predictions.",
      "C": "It's a type of pooling operation.",
      "D": "It is used solely for image compression."
    },
    "answer": "B",
    "explanation": "Attention mechanisms allow a neural network to focus on relevant parts of its input sequence when producing an output, rather than treating all parts equally.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 112,
    "question": "What is 'Adagrad' and what is its main limitation?",
    "options": {
      "A": "A type of activation function; it saturates quickly.",
      "B": "An optimizer that adapts learning rates for each parameter; its learning rates can become infinitesimally small.",
      "C": "A regularization technique; it adds too much noise.",
      "D": "A network architecture; it is computationally too heavy."
    },
    "answer": "B",
    "explanation": "Adagrad adapts learning rates based on past gradients. Its main limitation is that the accumulated squared gradients can lead to excessively small learning rates, causing training to halt prematurely.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 113,
    "question": "How do 'Generative Adversarial Networks (GANs)' learn to generate realistic data?",
    "options": {
      "A": "By directly copying and pasting parts of the training data.",
      "B": "Through a cooperative process where a Generator and Discriminator jointly learn from each other.",
      "C": "Through a competitive game where a Generator tries to fool a Discriminator, and the Discriminator tries to correctly identify real vs. fake data.",
      "D": "By minimizing the mean squared error between generated and real data."
    },
    "answer": "C",
    "explanation": "GANs operate on a minimax game theory principle: the generator tries to produce data indistinguishable from real data, while the discriminator tries to distinguish between real and generated data.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 114,
    "question": "What is the 'kernel size' in a convolutional layer, and how does it affect feature extraction?",
    "options": {
      "A": "The number of filters; more filters mean more general features.",
      "B": "The number of channels in the input image; it determines color depth.",
      "C": "The dimensions (width x height) of the filter; larger kernels capture more global features, smaller ones capture local features.",
      "D": "The stride of the convolution; larger kernels have larger strides."
    },
    "answer": "C",
    "explanation": "The kernel size defines the local receptive field of the filter. Larger kernels can capture broader patterns but also increase computational cost and parameter count.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 115,
    "question": "Why might 'Leaky ReLU' be preferred over 'ReLU' in some deep learning models?",
    "options": {
      "A": "Leaky ReLU is always positive, preventing negative activations.",
      "B": "Leaky ReLU introduces a small slope for negative inputs, preventing 'dying ReLUs' where neurons can become inactive.",
      "C": "Leaky ReLU computes faster than ReLU.",
      "D": "Leaky ReLU has a stronger vanishing gradient problem."
    },
    "answer": "B",
    "explanation": "Leaky ReLU assigns a small, non-zero gradient for negative inputs, preventing neurons from becoming permanently inactive (dying ReLUs), a common issue with standard ReLU.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 116,
    "question": "What is 'transfer learning', and why is it particularly useful in deep learning?",
    "options": {
      "A": "Training a model on different types of hardware.",
      "B": "Applying a pre-trained model to a new but related task, saving training time and requiring less data for the new task.",
      "C": "Moving learned knowledge between different layers of the same network.",
      "D": "Automatically generating new training data from existing data."
    },
    "answer": "B",
    "explanation": "Transfer learning leverages features learned from massive datasets by pre-trained models, which are often generalizable, thus speeding up training and improving performance on smaller, specific datasets.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 117,
    "question": "How does a 'bidirectional RNN' (BiRNN) differ from a standard RNN?",
    "options": {
      "A": "BiRNNs only process input in one direction, but faster.",
      "B": "BiRNNs process the input sequence in both forward and backward directions, allowing them to capture context from both past and future steps.",
      "C": "BiRNNs use convolutional layers instead of recurrent layers.",
      "D": "BiRNNs only use a single hidden layer."
    },
    "answer": "B",
    "explanation": "BiRNNs have two independent RNNs processing the input sequence, one in the forward direction and one in the backward direction, providing a richer understanding of context.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 118,
    "question": "What is the main limitation of using a very large 'batch size' during training?",
    "options": {
      "A": "It can lead to noisy gradients and slow convergence.",
      "B": "It requires less memory than smaller batch sizes.",
      "C": "It can lead to the model converging to sharp minimas, which might not generalize well.",
      "D": "It makes the model more prone to vanishing gradients."
    },
    "answer": "C",
    "explanation": "While large batch sizes can speed up training, they often converge to sharp minimas of the loss function, which tend to generalize less well than the flatter minimas found by smaller batch sizes.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 119,
    "question": "Describe the 'Encoder-Decoder' architecture commonly used in sequence-to-sequence models.",
    "options": {
      "A": "A single network that both encodes and decodes simultaneously.",
      "B": "An architecture where an encoder processes the input sequence into a fixed-length context vector, and a decoder then generates the output sequence from that context vector.",
      "C": "A network that only performs classification tasks.",
      "D": "A system for image segmentation without any convolutional layers."
    },
    "answer": "B",
    "explanation": "Encoder-decoder models are fundamental for tasks like machine translation. The encoder summarizes the input, and the decoder generates the output based on that summary.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 120,
    "question": "What is 'Word Embeddings' in NLP, and why are they important in deep learning?",
    "options": {
      "A": "A method to count word frequencies in a text.",
      "B": "A way to convert words into fixed-size, dense vector representations that capture semantic meaning and relationships between words, enabling neural networks to process text.",
      "C": "A technique for visualizing word clouds.",
      "D": "A process of translating text from one language to another."
    },
    "answer": "B",
    "explanation": "Word embeddings (e.g., Word2Vec, GloVe) represent words as numerical vectors, where words with similar meanings have similar vector representations, crucial for NLP models.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 121,
    "question": "How does 'RMSprop' optimizer differ from 'Adagrad'?",
    "options": {
      "A": "RMSprop uses a fixed learning rate for all parameters.",
      "B": "RMSprop keeps a decaying average of squared gradients, preventing the learning rate from becoming infinitesimally small like Adagrad.",
      "C": "RMSprop only considers the current gradient, not past ones.",
      "D": "RMSprop is only used for recurrent neural networks."
    },
    "answer": "B",
    "explanation": "RMSprop addresses Adagrad's aggressive decay by using an exponentially weighted moving average of squared gradients, allowing training to continue even after many updates.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 122,
    "question": "What is 'Sparsity' in the context of deep learning models?",
    "options": {
      "A": "The number of training examples used.",
      "B": "A condition where many weights or activations in a neural network are zero, which can lead to more efficient models.",
      "C": "The density of connections in a fully connected layer.",
      "D": "The lack of diverse data in the training set."
    },
    "answer": "B",
    "explanation": "Sparsity means many values are zero. In neural networks, sparse weights (e.g., from L1 regularization) or sparse activations (e.g., from ReLU) can make models more efficient and sometimes more robust.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 123,
    "question": "When would you typically use 'Softmax' versus 'Sigmoid' in the output layer of a neural network?",
    "options": {
      "A": "Softmax for regression, Sigmoid for classification.",
      "B": "Softmax for binary classification, Sigmoid for multi-class classification.",
      "C": "Softmax for multi-class classification, Sigmoid for binary classification.",
      "D": "They are interchangeable for all classification tasks."
    },
    "answer": "C",
    "explanation": "Sigmoid outputs a single probability between 0 and 1, suitable for binary classification. Softmax outputs a probability distribution over multiple classes, summing to 1.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 124,
    "question": "What is a 'Transformer' architecture, and what makes it powerful for NLP?",
    "options": {
      "A": "A type of CNN for image processing.",
      "B": "A neural network that relies solely on recurrent connections for sequence processing.",
      "C": "An architecture that uses self-attention mechanisms to weigh the importance of different parts of the input sequence, enabling parallelization and capturing long-range dependencies efficiently.",
      "D": "A model used for generative tasks without any discriminative component."
    },
    "answer": "C",
    "explanation": "Transformers, notably for NLP, moved away from recurrence, leveraging self-attention to process entire sequences in parallel, leading to significant breakthroughs in tasks like machine translation.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 125,
    "question": "Explain 'Data Augmentation' in the context of image classification.",
    "options": {
      "A": "Adding more real images to the dataset.",
      "B": "Generating synthetic images from scratch using GANs.",
      "C": "Applying various transformations (e.g., rotation, flip, crop) to existing training images to create new, diverse training samples, increasing dataset size and reducing overfitting.",
      "D": "Reducing the resolution of images to speed up training."
    },
    "answer": "C",
    "explanation": "Data augmentation is a common technique to artificially expand the training dataset by creating modified versions of existing images, improving model robustness and generalization.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 126,
    "question": "What is the 'embedding dimension' in a word embedding layer?",
    "options": {
      "A": "The number of words in the vocabulary.",
      "B": "The fixed size (number of features) of the vector representation for each word.",
      "C": "The length of the input sequence.",
      "D": "The number of layers in the embedding model."
    },
    "answer": "B",
    "explanation": "The embedding dimension specifies the size of the dense vector that each word is mapped to. A higher dimension can capture more semantic information.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 127,
    "question": "How does 'L1 Regularization' (Lasso) differ from 'L2 Regularization' (Ridge) in deep learning?",
    "options": {
      "A": "L1 encourages larger weights, L2 encourages smaller weights.",
      "B": "L1 penalizes the sum of squared weights, L2 penalizes the sum of absolute weights.",
      "C": "L1 tends to drive some weights to exactly zero (feature selection), while L2 shrinks weights towards zero but rarely to exactly zero.",
      "D": "L1 is used for classification, L2 for regression."
    },
    "answer": "C",
    "explanation": "L1 adds the absolute value of weights to the loss, promoting sparsity (some weights becoming zero). L2 adds the squared value of weights, shrinking them but not typically to exact zero.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 128,
    "question": "What is 'Knowledge Distillation' in deep learning?",
    "options": {
      "A": "Training a larger model using a smaller model's predictions.",
      "B": "Transferring knowledge from a large, complex 'teacher' model to a smaller, simpler 'student' model.",
      "C": "A method for automatically generating training data.",
      "D": "A technique to make models more interpretable by extracting key features."
    },
    "answer": "B",
    "explanation": "Knowledge distillation aims to compress the knowledge from a powerful teacher model into a smaller student model, often by having the student learn from the teacher's 'soft' targets (probability distributions).",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 129,
    "question": "What is the main advantage of 'SGD with Momentum' over plain SGD?",
    "options": {
      "A": "It always finds the global minimum faster.",
      "B": "It reduces oscillations and speeds up convergence by accumulating past gradients, helping to smooth out updates.",
      "C": "It removes the need for a learning rate.",
      "D": "It works only for very shallow networks."
    },
    "answer": "B",
    "explanation": "Momentum helps accelerate SGD in the relevant direction and dampens oscillations by adding a fraction of the update vector of the past step to the current update.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 130,
    "question": "Describe a scenario where a 'Generative Pre-trained Transformer (GPT)' model would be highly effective.",
    "options": {
      "A": "Image classification on a new dataset.",
      "B": "Real-time object detection in videos.",
      "C": "Generating human-like text, such as writing articles, answering questions, or creative content generation.",
      "D": "Time series forecasting for stock prices."
    },
    "answer": "C",
    "explanation": "GPT models are state-of-the-art for natural language generation tasks, thanks to their transformer architecture and large-scale pre-training on vast amounts of text data.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 131,
    "question": "What is 'Inception Module' in CNNs, and what problem does it address?",
    "options": {
      "A": "It's a simple sequential stack of convolutional layers.",
      "B": "It's a module that performs multiple parallel convolutions with different filter sizes and pooling operations, allowing the network to capture features at various scales and optimize computational efficiency.",
      "C": "It's a module specifically for recurrent connections in images.",
      "D": "It's an activation function that leads to very sparse activations."
    },
    "answer": "B",
    "explanation": "Inception modules (from GoogLeNet) allow the network to learn multiple feature representations at once, improving efficiency and performance by having different receptive fields.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 132,
    "question": "What is 'Self-Supervised Learning' in deep learning?",
    "options": {
      "A": "Learning directly from human feedback.",
      "B": "A type of supervised learning with extremely large datasets.",
      "C": "Learning representations from unlabeled data by creating pseudo-labels from the data itself (e.g., predicting missing parts of an input).",
      "D": "Training a model without any data whatsoever."
    },
    "answer": "C",
    "explanation": "Self-supervised learning generates supervision signals from the data itself, allowing models to be pre-trained on vast amounts of unlabeled data, crucial for tasks like language modeling or image representation learning.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 133,
    "question": "How do 'Gated Recurrent Units (GRUs)' simplify LSTMs while retaining similar performance?",
    "options": {
      "A": "GRUs remove all gates, making them simpler RNNs.",
      "B": "GRUs combine the input and forget gates into an update gate and merge the cell state and hidden state, reducing the number of parameters.",
      "C": "GRUs use convolutional operations instead of recurrent connections.",
      "D": "GRUs can only process short sequences, unlike LSTMs."
    },
    "answer": "B",
    "explanation": "GRUs are a simpler variant of LSTMs with fewer gates, making them computationally less expensive while still being effective at handling vanishing gradients and learning long-term dependencies.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 134,
    "question": "What is 'Adversarial Training' and why is it used in deep learning?",
    "options": {
      "A": "Training two models against each other to improve accuracy on standard data.",
      "B": "Training a model on adversarial examples (inputs intentionally perturbed to fool the model) to improve its robustness to such attacks.",
      "C": "A method to generate new synthetic data.",
      "D": "A form of unsupervised clustering."
    },
    "answer": "B",
    "explanation": "Adversarial training aims to make deep learning models more robust and less susceptible to adversarial attacks by including adversarial examples in the training data.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 135,
    "question": "What is 'Knowledge Graph Embedding' in deep learning?",
    "options": {
      "A": "Embedding text documents into a graph structure.",
      "B": "Representing entities and relations in a knowledge graph as low-dimensional vectors, enabling reasoning and prediction.",
      "C": "A method for visualizing complex knowledge graphs.",
      "D": "Converting images into graph structures for processing."
    },
    "answer": "B",
    "explanation": "Knowledge Graph Embeddings represent components of a knowledge graph (entities and relations) in a continuous vector space, allowing for computations and reasoning on the graph structure.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 136,
    "question": "How does a 'Sequence-to-Sequence' model with attention differ from a basic Encoder-Decoder model?",
    "options": {
      "A": "The attention mechanism allows the decoder to selectively focus on relevant parts of the input sequence at each decoding step, overcoming the fixed-size context vector limitation.",
      "B": "It uses convolutional layers instead of recurrent layers.",
      "C": "It can only process very short sequences.",
      "D": "It doesn't require an encoder."
    },
    "answer": "A",
    "explanation": "Basic encoder-decoder models struggle with long sequences due to a fixed-size context vector. Attention allows the decoder to 'look back' at different parts of the encoder's output, improving performance on long sequences.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 137,
    "question": "What is the concept of 'one-shot learning' in deep learning, and when is it useful?",
    "options": {
      "A": "Training a model with only one epoch.",
      "B": "Learning to classify new categories with very few (often one) training examples per category, useful in scenarios with limited data.",
      "C": "A type of adversarial training where only one generator is used.",
      "D": "A method for super-resolution of images."
    },
    "answer": "B",
    "explanation": "One-shot learning aims to learn from a single example. It's useful in domains like face recognition where acquiring many examples for each person is impractical.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 138,
    "question": "What is the 'bottleneck layer' in an autoencoder, and what is its significance?",
    "options": {
      "A": "The output layer of the decoder.",
      "B": "The layer with the largest number of neurons, increasing model capacity.",
      "C": "The layer with the smallest number of neurons, representing the compressed latent space, forcing the encoder to learn efficient representations.",
      "D": "The layer that handles input data pre-processing."
    },
    "answer": "C",
    "explanation": "The bottleneck layer (or latent space) in an autoencoder has fewer neurons than other layers, acting as a constraint that forces the network to learn a compact, meaningful representation of the input.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 139,
    "question": "How does 'Xavier Initialization' (Glorot Initialization) contribute to stable training in deep networks?",
    "options": {
      "A": "It sets all initial weights to zero.",
      "B": "It initializes weights from a distribution that keeps the variance of activations and gradients roughly constant across layers, preventing vanishing/exploding gradients.",
      "C": "It randomly samples weights from a uniform distribution without specific scaling.",
      "D": "It only initializes bias terms, not weights."
    },
    "answer": "B",
    "explanation": "Xavier initialization aims to set initial weights such that the scale of activations and gradients is maintained through the network, allowing for smoother training, especially with Sigmoid/Tanh activations.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 140,
    "question": "What is a 'Generative Adversarial Network (GAN)' primarily used for?",
    "options": {
      "A": "Classification of existing data.",
      "B": "Anomaly detection.",
      "C": "Generating new, realistic data instances that resemble the training data.",
      "D": "Performing dimensionality reduction on large datasets."
    },
    "answer": "C",
    "explanation": "GANs are powerful generative models capable of creating new data, such as images, audio, or text, that are highly realistic.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 141,
    "question": "In the context of multi-label classification, which loss function is generally more appropriate than categorical cross-entropy?",
    "options": {
      "A": "Mean Squared Error",
      "B": "Binary Cross-Entropy (applied independently for each label)",
      "C": "Kullback-Leibler Divergence",
      "D": "Hinge Loss"
    },
    "answer": "B",
    "explanation": "For multi-label classification (where an instance can belong to multiple categories simultaneously), binary cross-entropy is applied independently for each label, often combined with a sigmoid activation function in the output layer.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 142,
    "question": "What is the purpose of the 'Temperature' parameter in the Softmax function when used in knowledge distillation or large language models?",
    "options": {
      "A": "To control the learning rate of the model.",
      "B": "To adjust the 'sharpness' of the probability distribution, making it smoother (higher temperature) or sharper (lower temperature).",
      "C": "To normalize the input logits to be within a specific range.",
      "D": "To increase the number of classes in the output."
    },
    "answer": "B",
    "explanation": "Temperature scaling in softmax is used to soften or sharpen the output probability distribution. Higher temperature leads to softer probabilities (more uniform), while lower temperature leads to sharper probabilities (more confident).",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 143,
    "question": "Describe the architecture of a 'Variational Autoencoder (VAE)'.",
    "options": {
      "A": "A simple encoder-decoder structure for classification.",
      "B": "An autoencoder where the encoder outputs parameters of a probability distribution (mean and variance) over the latent space, from which samples are drawn for the decoder, enabling generative capabilities.",
      "C": "A network that uses only convolutional layers for image generation.",
      "D": "A type of RNN specifically designed for time series forecasting."
    },
    "answer": "B",
    "explanation": "VAEs are generative models that learn a probabilistic mapping from input to latent space, allowing for smooth interpolations and sampling from the learned distribution.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 144,
    "question": "What is 'Recurrent Dropout', and why is it specifically useful for RNNs?",
    "options": {
      "A": "Dropping out entire layers in an RNN.",
      "B": "Applying dropout to the recurrent connections (hidden state) in an RNN, which helps in regularization without disrupting the sequence-to-sequence flow of information.",
      "C": "Dropping out inputs to the RNN at random.",
      "D": "A method to reduce the number of recurrent units."
    },
    "answer": "B",
    "explanation": "Applying standard dropout to every time step in an RNN can hinder its ability to learn long-term dependencies. Recurrent dropout applies the same dropout mask at each time step, preserving the memory flow.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 145,
    "question": "What is 'Focal Loss' and in what scenario is it particularly beneficial?",
    "options": {
      "A": "A loss function for regression tasks.",
      "B": "A loss function designed to address class imbalance by down-weighting the loss contribution of well-classified examples, particularly useful in object detection where background classes dominate.",
      "C": "A loss function for generative models like GANs.",
      "D": "A loss function that prevents vanishing gradients."
    },
    "answer": "B",
    "explanation": "Focal Loss aims to solve the problem of class imbalance in object detection by focusing training on hard, misclassified examples.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 146,
    "question": "Explain the concept of 'Positional Encoding' in Transformer models.",
    "options": {
      "A": "Encoding the position of an object in an image.",
      "B": "Encoding the absolute or relative position of tokens in the input sequence, as Transformers lack inherent recurrence or convolution to process order.",
      "C": "Encoding the type of attention mechanism used.",
      "D": "Encoding the color channels of an image."
    },
    "answer": "B",
    "explanation": "Since Transformers process sequences in parallel without inherent order, positional encodings are added to the input embeddings to provide information about the relative or absolute position of tokens.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 147,
    "question": "What is 'Grid Search' and 'Random Search' used for in deep learning?",
    "options": {
      "A": "Searching for optimal weight initializations.",
      "B": "Methods for hyperparameter optimization, where Grid Search systematically tries all combinations and Random Search samples combinations randomly.",
      "C": "Techniques for data augmentation.",
      "D": "Algorithms for gradient clipping."
    },
    "answer": "B",
    "explanation": "These are common strategies for hyperparameter tuning. Random Search is often more efficient for high-dimensional hyperparameter spaces.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 148,
    "question": "What is a 'Metric Learning' approach in deep learning?",
    "options": {
      "A": "Learning to classify different types of metrics.",
      "B": "Learning a distance metric or similarity function between data points, often used in tasks like face recognition or recommendation systems.",
      "C": "A method for compressing large models.",
      "D": "Learning to generate new evaluation metrics."
    },
    "answer": "B",
    "explanation": "Metric learning aims to learn an embedding space where similar data points are close together and dissimilar points are far apart, based on a learned distance function.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 149,
    "question": "How does 'Cyclical Learning Rates' (CLR) contribute to deep learning training?",
    "options": {
      "A": "By keeping the learning rate constant throughout training.",
      "B": "By varying the learning rate between a lower and upper bound in a cyclical manner, often leading to faster convergence and better final accuracy.",
      "C": "By always decreasing the learning rate exponentially.",
      "D": "By setting the learning rate based on the current loss."
    },
    "answer": "B",
    "explanation": "CLR allows the learning rate to oscillate between reasonable boundaries, helping the model escape saddle points and explore the loss landscape more effectively.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 150,
    "question": "What is the 'Dice Coefficient' often used for in deep learning, particularly in medical imaging?",
    "options": {
      "A": "To measure image brightness.",
      "B": "To evaluate the similarity or overlap between two sets, commonly used as a metric for image segmentation tasks.",
      "C": "To count the number of objects in an image.",
      "D": "To classify tumors as malignant or benign."
    },
    "answer": "B",
    "explanation": "The Dice Coefficient (or F1-score) is a popular metric to quantify the similarity between a predicted segmentation mask and the ground truth mask.",
    "topic": "Deep Learning",
    "difficulty": "Medium"
  },
  {
    "id": 151,
    "question": "In the context of CNNs, what does 'Dilated Convolution' (or Atrous Convolution) achieve, and when is it useful?",
    "options": {
      "A": "It compresses the feature maps by reducing resolution.",
      "B": "It applies a filter with gaps between its elements, increasing the receptive field without increasing the number of parameters or losing resolution, useful for semantic segmentation.",
      "C": "It adds more padding to the input image.",
      "D": "It's a faster way to perform standard convolution."
    },
    "answer": "B",
    "explanation": "Dilated convolutions allow filters to cover a larger area of the input without increasing the number of weights, capturing more context while preserving resolution, particularly beneficial in dense prediction tasks like segmentation.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 152,
    "question": "What is the 'curse of dimensionality' in the context of deep learning, and how do deep neural networks implicitly mitigate it?",
    "options": {
      "A": "It refers to the problem of having too many layers; mitigated by reducing network depth.",
      "B": "It's the phenomenon where the amount of data needed to generalize accurately grows exponentially with the number of features; deep networks mitigate it by learning hierarchical, low-dimensional representations (feature learning) from the high-dimensional input.",
      "C": "It's the problem of slow training on high-dimensional data; mitigated by using GPUs.",
      "D": "It describes the difficulty of visualizing high-dimensional data; deep networks solve it by providing visualization tools."
    },
    "answer": "B",
    "explanation": "Deep networks overcome the curse of dimensionality by discovering efficient, compressed, and more abstract representations of the data in lower-dimensional latent spaces.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 153,
    "question": "Beyond vanishing/exploding gradients, what are other significant challenges in training very deep neural networks, and how are they addressed?",
    "options": {
      "A": "Only hardware limitations; addressed by using more powerful GPUs.",
      "B": "Optimization difficulties (e.g., local minima, saddle points, poor initialization, degradation problem); addressed by advanced optimizers (Adam), Batch Normalization, residual connections, and better initialization strategies.",
      "C": "Lack of data; addressed by collecting more data.",
      "D": "Only overfitting; addressed by increasing model size."
    },
    "answer": "B",
    "explanation": "Deep networks face several training hurdles. Batch Normalization stabilizes training, residual connections help against degradation, and adaptive optimizers (like Adam) navigate complex loss landscapes more effectively.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 154,
    "question": "Elaborate on the 'Self-Attention Mechanism' as used in Transformer models. How does it enable long-range dependency capture?",
    "options": {
      "A": "It only allows neurons to attend to their immediate neighbors.",
      "B": "It computes a weighted sum of all other input elements, where the weights are dynamically calculated based on the similarity (query-key dot product) between the current element and all other elements, allowing it to capture dependencies regardless of distance.",
      "C": "It processes sequences purely through recurrence.",
      "D": "It uses convolutional filters to identify dependencies."
    },
    "answer": "B",
    "explanation": "Self-attention allows each element in a sequence to attend to all other elements, generating a context-aware representation. This global view enables it to model dependencies over arbitrary distances, unlike RNNs that struggle with long-range dependencies.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 155,
    "question": "What is 'Optimal Transport' theory, and how is it being applied in advanced GAN architectures (e.g., Wasserstein GANs)?",
    "options": {
      "A": "A theory for efficient data loading; used to speed up training.",
      "B": "A mathematical framework for comparing probability distributions; used in WGANs to define a more stable and meaningful distance metric (Earth Mover's Distance) between real and generated data distributions, leading to better training stability and sample quality.",
      "C": "A method to optimize network topology; applied to find the best network size.",
      "D": "A technique for compressing models; used to reduce model size."
    },
    "answer": "B",
    "explanation": "WGANs utilize the Earth Mover's Distance (a form of optimal transport) as their loss function, which provides a smoother gradient and better convergence properties than standard GANs' Jensen-Shannon divergence, especially when distributions are non-overlapping.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 156,
    "question": "Discuss the 'Inductive Bias' of Convolutional Neural Networks (CNNs).",
    "options": {
      "A": "CNNs have no inductive bias, learning everything from scratch.",
      "B": "CNNs are biased towards capturing global, amorphous patterns.",
      "C": "Their inductive biases include local connectivity, shared weights (parameter sharing), and spatial pooling, which make them highly effective for processing grid-like data like images by exploiting the spatial locality and translation invariance of features.",
      "D": "CNNs are biased towards processing sequential data."
    },
    "answer": "C",
    "explanation": "These architectural choices are built-in assumptions that help CNNs learn efficiently from visual data, making them particularly well-suited for image-related tasks.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 157,
    "question": "Explain 'Meta-Learning' (Learning to Learn) and provide an example of its application in deep learning.",
    "options": {
      "A": "Training a model to classify metadata.",
      "B": "Training a model to learn how to learn new tasks or adapt quickly to new environments with limited data, often by learning good initializations or optimization strategies. Example: Few-shot learning in image classification.",
      "C": "Using a meta-analysis of multiple deep learning research papers.",
      "D": "A technique for converting deep learning models to shallow models."
    },
    "answer": "B",
    "explanation": "Meta-learning trains a model on a distribution of tasks, allowing it to generalize quickly to new tasks with minimal additional training, e.g., MAML (Model-Agnostic Meta-Learning).",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 158,
    "question": "What is the 'manifold hypothesis' in deep learning and its implications for representation learning?",
    "options": {
      "A": "All data lies on a single, linear manifold.",
      "B": "The hypothesis that high-dimensional data, despite its apparent complexity, often lies on or close to a low-dimensional manifold; deep learning aims to discover and disentangle these underlying manifolds for effective representation.",
      "C": "It states that deep networks can only learn simple, flat representations.",
      "D": "It's a theory about the computational resources required for training."
    },
    "answer": "B",
    "explanation": "The manifold hypothesis suggests that deep learning's success stems from its ability to learn these intrinsically low-dimensional structures from high-dimensional data, leading to more meaningful representations.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 159,
    "question": "How do 'Capsule Networks' (CapsNets) propose to improve upon CNNs, particularly regarding spatial hierarchies and viewpoint invariance?",
    "options": {
      "A": "CapsNets simply use more layers than CNNs.",
      "B": "CapsNets replace scalar-output feature detectors with vector-output 'capsules' and use 'routing-by-agreement' to group related capsules, aiming to represent hierarchical relationships and handle viewpoint changes better than traditional pooling in CNNs.",
      "C": "CapsNets remove all pooling layers and use only dense connections.",
      "D": "CapsNets are designed only for text classification."
    },
    "answer": "B",
    "explanation": "CapsNets, introduced by Hinton, attempt to overcome some limitations of CNNs, like their struggle with varying viewpoints, by explicitly modeling part-whole relationships and pose information within vector-output capsules.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 160,
    "question": "Explain the concept of 'Disentangled Representations' in deep learning and why they are desirable.",
    "options": {
      "A": "Representations where different features are mixed together.",
      "B": "Representations where each latent dimension or feature corresponds to a single, independent explanatory factor of variation in the data (e.g., color, shape, size), making models more interpretable and robust to domain shifts.",
      "C": "Representations that are difficult to visualize.",
      "D": "Representations that are only useful for generative tasks."
    },
    "answer": "B",
    "explanation": "Disentangled representations are highly sought after as they improve interpretability, allow for more controlled generation, and can enhance transferability and robustness of models.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 161,
    "question": "What is the 'Neural Radiance Field (NeRF)' technique, and what major breakthrough does it offer in 3D scene representation?",
    "options": {
      "A": "A method for training very deep neural networks efficiently.",
      "B": "A novel approach that represents a 3D scene as a continuous volumetric function, optimized using a neural network, capable of rendering new views of complex scenes with unprecedented photorealism.",
      "C": "A technique for converting 2D images to 3D meshes directly.",
      "D": "A type of recurrent network for 3D object tracking."
    },
    "answer": "B",
    "explanation": "NeRF uses a small neural network to map 3D coordinates (x,y,z) and viewing directions to color and volume density, allowing for highly realistic novel view synthesis from a few input images.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 162,
    "question": "Discuss the trade-offs between 'Model Parallelism' and 'Data Parallelism' in distributed deep learning training.",
    "options": {
      "A": "Model parallelism means training multiple models on the same data; data parallelism means training one model on one machine.",
      "B": "Model parallelism distributes different parts of a single model across multiple devices for large models; data parallelism replicates the model on multiple devices and distributes data, suitable for large datasets. Trade-offs involve communication overhead, load balancing, and synchronization.",
      "C": "Model parallelism is for CPUs, data parallelism is for GPUs.",
      "D": "They are two names for the same technique."
    },
    "answer": "B",
    "explanation": "Choosing between model and data parallelism depends on the size of the model and the dataset, and the communication bandwidth between devices.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 163,
    "question": "Explain 'Diffusion Models' and their recent impact on generative AI.",
    "options": {
      "A": "Models that simulate the diffusion of information in social networks.",
      "B": "Generative models that learn to reverse a gradual 'noising' process applied to data, iteratively denoising random noise to produce realistic data samples. They have achieved state-of-the-art results in image and audio generation.",
      "C": "Models that measure the spread of errors in a neural network.",
      "D": "A new type of activation function that diffuses gradients."
    },
    "answer": "B",
    "explanation": "Diffusion models (like DALL-E 2, Stable Diffusion) generate data by reversing a Markov chain of noise addition, showing remarkable quality and diversity in their outputs.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 164,
    "question": "What is the 'Pruning' technique in deep learning, and what is its main goal?",
    "options": {
      "A": "Adding more neurons to a network.",
      "B": "Removing redundant or less important weights/neurons from a trained neural network to reduce model size and computational cost, without significant loss of accuracy.",
      "C": "Growing a network by adding layers dynamically.",
      "D": "Randomly initializing weights before training."
    },
    "answer": "B",
    "explanation": "Pruning helps in model compression and deployment on resource-constrained devices, by making models more sparse.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 165,
    "question": "How does 'Graph Neural Networks (GNNs)' extend the capabilities of deep learning to non-Euclidean data?",
    "options": {
      "A": "GNNs convert all data into Euclidean space before processing.",
      "B": "GNNs are designed to operate directly on graph-structured data by aggregating information from a node's neighbors, learning representations that capture graph topology and node features, enabling tasks like node classification and link prediction.",
      "C": "GNNs are a type of CNN for irregular grids.",
      "D": "GNNs are only applicable to very small graphs."
    },
    "answer": "B",
    "explanation": "GNNs allow deep learning to be applied to relationships within data (like social networks, molecules) where traditional grid-based (image, text) models are not suitable.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 166,
    "question": "What is the 'Double Descent' phenomenon observed in deep learning, and why does it challenge traditional statistical learning theory?",
    "options": {
      "A": "It's when the loss function decreases, then increases, then decreases again.",
      "B": "It describes a phenomenon where, as model capacity increases, performance first improves, then worsens (classical overfitting), but then improves again (second descent), even beyond the point of perfect fit on training data. This challenges the bias-variance trade-off notion by showing that overfitting training data can lead to good generalization in overparameterized models.",
      "C": "It refers to the two-step process of training a GAN.",
      "D": "It's a problem where two optimizers are used simultaneously."
    },
    "answer": "B",
    "explanation": "Double descent suggests that highly overparameterized models can generalize well, which goes against the classic bias-variance trade-off that predicts worse generalization with increasing complexity past an optimal point.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 167,
    "question": "How does 'Reinforcement Learning from Human Feedback (RLHF)' improve large language models?",
    "options": {
      "A": "It trains the model solely on human-generated text.",
      "B": "It fine-tunes a pre-trained language model using human preferences (rewards) to align its outputs more closely with human values and intentions, reducing harmful, biased, or unhelpful responses.",
      "C": "It makes the model explain its reasoning to humans.",
      "D": "It uses human input to generate new training data."
    },
    "answer": "B",
    "explanation": "RLHF is critical for aligning large models like GPT-3.5/4 with human expectations, making them safer, more helpful, and more coherent.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 168,
    "question": "What are 'Latent Diffusion Models (LDMs)' and how do they improve upon earlier diffusion models?",
    "options": {
      "A": "They generate text descriptions from images.",
      "B": "LDMs operate in a compressed, lower-dimensional latent space learned by an autoencoder, rather than directly on high-resolution pixel space. This significantly reduces computational cost and memory requirements while retaining high generative quality.",
      "C": "They are used for anomaly detection in time series.",
      "D": "They can only generate black and white images."
    },
    "answer": "B",
    "explanation": "LDMs (e.g., Stable Diffusion) enable high-resolution image generation efficiently by performing the diffusion process in a more compact latent representation.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 169,
    "question": "Explain 'Federated Learning' and its benefits in deep learning applications.",
    "options": {
      "A": "Training one model on a centralized server.",
      "B": "A decentralized approach where a global model is trained collaboratively by multiple client devices (e.g., mobile phones) without exchanging raw data, only model updates, thus preserving data privacy.",
      "C": "A method to distribute data across multiple GPUs on a single server.",
      "D": "Learning from a diverse set of datasets from different domains."
    },
    "answer": "B",
    "explanation": "Federated learning is crucial for privacy-sensitive applications where data cannot be centrally aggregated but distributed learning is still desired.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 170,
    "question": "What is the 'Perceiver IO' model, and what problem does it aim to solve in deep learning architectures?",
    "options": {
      "A": "A model designed exclusively for tabular data.",
      "B": "A general-purpose neural network architecture that can handle diverse modalities (images, audio, text) by processing high-dimensional inputs through a latent bottleneck and cross-attention mechanisms, aiming for a unified, scalable approach.",
      "C": "A model that only processes structured data.",
      "D": "A small model for edge devices."
    },
    "answer": "B",
    "explanation": "Perceiver IO aims to address the quadratic complexity of standard Transformers with large inputs by using an attention-based bottleneck, making it more scalable to very high-dimensional data across different modalities.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 171,
    "question": "How do 'Hypernetworks' work, and what is their potential application in deep learning?",
    "options": {
      "A": "Networks that are extremely large in terms of parameters.",
      "B": "Neural networks whose weights are generated by another neural network (the hypernetwork), enabling dynamic weight generation, meta-learning, or adapting weights to specific inputs.",
      "C": "Networks that operate only on hyperparameters.",
      "D": "Networks that learn to compress other networks."
    },
    "answer": "B",
    "explanation": "Hypernetworks allow for more flexible and adaptive models, especially useful in contexts like few-shot learning, where weights need to be tailored to specific, novel tasks or inputs.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 172,
    "question": "What is 'Adversarial Examples' in deep learning, and why are they a significant concern?",
    "options": {
      "A": "Examples of data that are easy for models to classify.",
      "B": "Inputs intentionally perturbed (often imperceptibly to humans) to cause a deep learning model to misclassify or make incorrect predictions, highlighting a fragility and lack of robustness in current models.",
      "C": "Examples that are generated by a GAN's discriminator.",
      "D": "Data points that represent outliers in a dataset."
    },
    "answer": "B",
    "explanation": "Adversarial examples reveal vulnerabilities in deep learning models and are a major area of research for improving model robustness, particularly in safety-critical applications.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 173,
    "question": "Explain 'Mixture of Experts (MoE)' models and their advantage in scaling large language models.",
    "options": {
      "A": "Models that combine predictions from a fixed set of pre-trained models.",
      "B": "Architectures that route different parts of the input to different 'expert' sub-networks, allowing for a vast increase in model capacity without a proportional increase in computational cost per inference, enabling the training of extremely large models.",
      "C": "Models that simplify complex tasks into multiple smaller, independent tasks.",
      "D": "Models that are designed to handle only specific, specialized tasks."
    },
    "answer": "B",
    "explanation": "MoE models use a 'gating network' to dynamically select which experts process which parts of the input, leading to models with billions of parameters but efficient inference time.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 174,
    "question": "What is 'Neuro-Symbolic AI' and how does it relate to deep learning?",
    "options": {
      "A": "It's a purely symbolic AI approach without neural networks.",
      "B": "It's an emerging field that combines the strengths of neural networks (e.g., pattern recognition, learning from data) with symbolic AI (e.g., reasoning, knowledge representation) to achieve more robust, interpretable, and generalizable intelligence.",
      "C": "It refers to the study of the human brain's neural networks.",
      "D": "It's a method for visualizing neural network activation patterns."
    },
    "answer": "B",
    "explanation": "Neuro-symbolic AI seeks to overcome limitations of purely connectionist (deep learning) or symbolic systems by integrating their complementary capabilities.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 175,
    "question": "Describe the 'Universal Approximation Theorem' for neural networks and its practical implications.",
    "options": {
      "A": "It states that a neural network can approximate any continuous function with only one hidden layer and linear activation.",
      "B": "It states that a feedforward neural network with a single hidden layer containing a finite number of neurons (with non-linear activation) can approximate any continuous function to arbitrary accuracy. Its implication is that deep networks are not strictly necessary for expressivity but often offer practical advantages in learning complex functions and representations.",
      "C": "It states that deep networks can approximate only linear functions.",
      "D": "It's a theorem about the optimal learning rate for training."
    },
    "answer": "B",
    "explanation": "The theorem highlights the theoretical power of even shallow networks, but in practice, deeper architectures often make the learning process more efficient and effective for high-dimensional, complex data.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 176,
    "question": "What is 'Contrastive Learning' and how is it used for self-supervised representation learning?",
    "options": {
      "A": "Learning by contrasting different types of loss functions.",
      "B": "A technique that learns representations by pushing similar (positive) pairs of data points closer together and dissimilar (negative) pairs farther apart in an embedding space, without explicit labels.",
      "C": "A method to generate adversarial examples.",
      "D": "Learning by comparing model predictions to human evaluations."
    },
    "answer": "B",
    "explanation": "Contrastive learning has been highly successful in self-supervised learning for computer vision (e.g., SimCLR, MoCo) and NLP, allowing models to learn robust representations from unlabeled data.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 177,
    "question": "Explain 'Bayesian Neural Networks (BNNs)' and their key advantages over standard ANNs.",
    "options": {
      "A": "BNNs use Bayesian optimization for hyperparameter tuning.",
      "B": "BNNs model probability distributions over weights and activations, rather than point estimates, allowing them to quantify uncertainty in predictions and offer better calibration, especially crucial in safety-critical applications.",
      "C": "BNNs are only used for unsupervised learning tasks.",
      "D": "BNNs train significantly faster than ANNs."
    },
    "answer": "B",
    "explanation": "BNNs provide a measure of confidence for their predictions, which is vital in applications like autonomous driving or medical diagnosis where knowing 'how sure' the model is matters.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 178,
    "question": "What is 'Graph Attention Network (GAT)' and how does it improve upon standard GNNs?",
    "options": {
      "A": "GAT applies attention only to the global graph structure.",
      "B": "GAT incorporates an attention mechanism, allowing it to assign different importance weights to different neighbors of a node during information aggregation, making it more flexible and powerful than fixed-weight aggregation in standard GNNs.",
      "C": "GAT is a type of convolutional network for images.",
      "D": "GAT removes all connections in a graph."
    },
    "answer": "B",
    "explanation": "By learning the importance of neighbors, GATs can better handle varying neighborhood structures and achieve state-of-the-art results on many graph learning tasks.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 179,
    "question": "How does 'Mixture Density Network (MDN)' extend standard neural networks for regression tasks?",
    "options": {
      "A": "MDNs predict a single numerical value.",
      "B": "Instead of outputting a single prediction, MDNs predict the parameters (means, variances, mixing coefficients) of a mixture of probability distributions, allowing them to model multimodal or uncertain relationships in the data.",
      "C": "MDNs are used only for classification problems.",
      "D": "MDNs reduce the dimensionality of the input data."
    },
    "answer": "B",
    "explanation": "MDNs are useful when the output variable might have multiple plausible values for a given input, providing a richer probabilistic output rather than a single point estimate.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 180,
    "question": "What is 'Zero-Shot Learning' and 'Few-Shot Learning' in deep learning, and how do they differ?",
    "options": {
      "A": "Zero-shot learns from no data; few-shot learns from much data.",
      "B": "Zero-shot learning classifies instances of classes unseen during training, often by leveraging semantic information (e.g., word embeddings). Few-shot learning classifies new classes with very few (e.g., 1-5) labeled examples per class. Both aim to generalize to new categories with limited supervision.",
      "C": "Zero-shot is for regression; few-shot is for classification.",
      "D": "Zero-shot only applies to image data; few-shot to text."
    },
    "answer": "B",
    "explanation": "These are crucial areas of research for making AI models more adaptable and less data-hungry for novel tasks or categories.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 181,
    "question": "What is the concept of 'Causal Inference' in deep learning, and why is it important for robust AI systems?",
    "options": {
      "A": "Inferring the cause of model errors.",
      "B": "Moving beyond mere correlation to understand cause-and-effect relationships from data, making models more robust to distribution shifts, generalizable, and less prone to spurious correlations, crucial for decision-making systems.",
      "C": "Inferring the initial cause of a neural network's weights.",
      "D": "Identifying direct links between neurons in a network."
    },
    "answer": "B",
    "explanation": "Causal inference aims to build AI systems that can reason about interventions and counterfactuals, leading to more reliable and trustworthy AI.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 182,
    "question": "How do 'Spiking Neural Networks (SNNs)' differ from traditional Artificial Neural Networks (ANNs), and what are their potential advantages?",
    "options": {
      "A": "SNNs use continuous activations; ANNs use discrete spikes.",
      "B": "SNNs mimic biological neurons more closely by transmitting information via discrete 'spikes' (events) over time, rather than continuous values. They offer potential advantages in energy efficiency and event-driven processing, particularly for neuromorphic hardware.",
      "C": "SNNs are only used for text processing; ANNs for images.",
      "D": "SNNs train much faster on conventional hardware."
    },
    "answer": "B",
    "explanation": "SNNs are a third generation of neural networks, aiming to bridge the gap between biological and artificial intelligence by incorporating temporal dynamics and sparsity.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 183,
    "question": "Explain 'Neural Ordinary Differential Equations (NODEs)' and their unique property.",
    "options": {
      "A": "NODEs are a type of recurrent neural network for time series.",
      "B": "NODEs parameterize the derivative of the hidden state, allowing for continuous-depth neural networks. Their unique property is that they can learn arbitrarily complex continuous transformations and model irregularly sampled time series more effectively than discrete-layer networks.",
      "C": "NODEs replace ODEs in scientific simulations.",
      "D": "NODEs only work with linear activations."
    },
    "answer": "B",
    "explanation": "NODEs represent the hidden state transformations as a continuous process, enabling benefits like memory efficiency during training and handling variable-length inputs more naturally.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 184,
    "question": "What is the 'Maximum Mean Discrepancy (MMD)' loss function, and where is it applied in deep learning?",
    "options": {
      "A": "A loss for standard classification tasks.",
      "B": "A non-parametric distance measure between two probability distributions (e.g., real and generated data), used as a loss function in generative models (like MMD-GANs) or in domain adaptation to reduce distribution shift.",
      "C": "A loss function for sequence generation.",
      "D": "A measure of model capacity."
    },
    "answer": "B",
    "explanation": "MMD aims to make the distribution of generated data match the distribution of real data by minimizing the 'discrepancy' between their empirical kernel embeddings.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 185,
    "question": "How do 'Equivariant Neural Networks' leverage symmetries in data, and what is their advantage?",
    "options": {
      "A": "They remove all symmetries from the input data.",
      "B": "They are designed such that if the input data is transformed (e.g., rotated, translated), the network's output transforms in a predictable, corresponding way. This hardcodes useful symmetries, leading to greater parameter efficiency and better generalization, especially in physics or medical imaging.",
      "C": "They only work with perfectly symmetric data.",
      "D": "They introduce random asymmetries to data."
    },
    "answer": "B",
    "explanation": "Equivariant networks are particularly powerful for tasks where underlying symmetries (like rotation or translation in images, or permutation in sets) are known and can be exploited to build more robust and data-efficient models.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 186,
    "question": "What is 'Model Quantization' in deep learning, and why is it important for deployment?",
    "options": {
      "A": "Adding more layers to a model.",
      "B": "Reducing the precision of the numerical representations of weights and activations (e.g., from 32-bit floating point to 8-bit integers) to reduce model size, memory footprint, and computational cost, crucial for deploying models on edge devices.",
      "C": "Measuring the quality of the model's predictions.",
      "D": "Making the model's architecture more complex."
    },
    "answer": "B",
    "explanation": "Quantization is a key technique for model compression and optimization, enabling deep learning models to run on devices with limited resources (e.g., mobile phones, IoT devices).",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 187,
    "question": "Explain 'Attention Is All You Need' and its paradigm shift in sequence modeling.",
    "options": {
      "A": "It argued that only attention mechanisms are needed for image classification.",
      "B": "It introduced the Transformer architecture, demonstrating that self-attention alone (without recurrence or convolution) could achieve state-of-the-art results in machine translation, enabling parallelization of training and superior long-range dependency modeling.",
      "C": "It proved that deep learning doesn't need any form of memory.",
      "D": "It emphasized the importance of using only a single large attention head."
    },
    "answer": "B",
    "explanation": "This seminal paper revolutionized NLP by showing that the sequence-to-sequence problem could be solved more efficiently and effectively by relying solely on attention mechanisms.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 188,
    "question": "What is 'Adversarial Machine Learning' more broadly, beyond just adversarial examples?",
    "options": {
      "A": "Machine learning used to create better video games.",
      "B": "A field that studies how machine learning models can be attacked and how to make them more robust against such attacks, encompassing data poisoning, model evasion, and model inversion attacks.",
      "C": "Learning where the training data is generated by an adversary.",
      "D": "Machine learning focused on ethical considerations only."
    },
    "answer": "B",
    "explanation": "Adversarial machine learning is a critical area for building trustworthy AI, as models deployed in real-world scenarios must be resilient to malicious manipulation.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 189,
    "question": "How does 'Reinforcement Learning' (RL) differ from supervised and unsupervised learning in deep learning, and what's a core challenge?",
    "options": {
      "A": "RL learns from labeled data like supervised learning.",
      "B": "RL learns by interacting with an environment, receiving rewards or penalties, to learn an optimal policy (sequence of actions) without explicit labels. A core challenge is the 'exploration-exploitation' dilemma and sparse rewards.",
      "C": "RL aims to find hidden patterns in unlabeled data.",
      "D": "RL is only used for image generation tasks."
    },
    "answer": "B",
    "explanation": "RL's distinct learning paradigm makes it suitable for decision-making tasks, but its reliance on sequential actions and delayed rewards introduces unique challenges.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 190,
    "question": "What is 'Neural Architecture Search (NAS)' and its primary goal?",
    "options": {
      "A": "Manually designing the best neural network architectures.",
      "B": "Automating the design of optimal neural network architectures for a given task, often using reinforcement learning or evolutionary algorithms to search through a vast space of possible configurations.",
      "C": "Searching for the best hyperparameters for a fixed architecture.",
      "D": "A method for visualizing neural network layers."
    },
    "answer": "B",
    "explanation": "NAS aims to alleviate the burden of expert-driven architectural design, potentially leading to more efficient or accurate models than human-designed ones.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 191,
    "question": "Explain 'Convex Optimization' and why standard deep learning is non-convex.",
    "options": {
      "A": "Convex optimization guarantees finding a global minimum with any optimizer; deep learning is convex.",
      "B": "Convex optimization deals with convex functions where any local minimum is also a global minimum, ensuring easy optimization. Standard deep learning is non-convex because of non-linear activations and multiple layers, leading to complex, multimodal loss landscapes with many local minima and saddle points.",
      "C": "Convex optimization only works with discrete variables.",
      "D": "Deep learning uses convex functions but with many variables."
    },
    "answer": "B",
    "explanation": "The non-convexity of deep learning's optimization problem is a fundamental challenge, making optimization more difficult but also allowing for the learning of highly complex functions.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 192,
    "question": "What is 'Continual Learning' (or Lifelong Learning) in deep learning, and why is it important?",
    "options": {
      "A": "Training models continuously on the same data.",
      "B": "The ability of a model to learn a sequence of tasks incrementally, without forgetting previously learned knowledge (catastrophic forgetting), crucial for AI systems that need to adapt to new information over time in real-world scenarios.",
      "C": "Learning tasks simultaneously in parallel.",
      "D": "A technique to make training datasets larger."
    },
    "answer": "B",
    "explanation": "Continual learning aims to mimic human-like learning, where new knowledge is acquired without erasing old knowledge, a key step towards more adaptive and intelligent AI.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 193,
    "question": "How does 'Mixture-of-Softmaxes' (MoS) improve upon standard softmax in language modeling?",
    "options": {
      "A": "MoS uses a single, very large softmax layer.",
      "B": "Instead of a single large softmax over the entire vocabulary, MoS uses a mixture of smaller softmax components, which can more effectively model the complex, multimodal distribution of words and scale better for very large vocabularies.",
      "C": "MoS removes the need for any softmax layer.",
      "D": "MoS is only used for image classification."
    },
    "answer": "B",
    "explanation": "MoS provides a more flexible and efficient way to handle the output distribution over extremely large vocabularies common in language models, improving expressiveness and reducing computational load.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 194,
    "question": "What is 'Causality Extraction' in NLP, and why is it a challenging task for deep learning?",
    "options": {
      "A": "Extracting all nouns from a text.",
      "B": "Identifying cause-and-effect relationships from unstructured text, which is challenging because deep learning models often learn correlations rather than true causal links, and identifying causality requires deep understanding of context and common sense reasoning.",
      "C": "Extracting the most frequent words in a document.",
      "D": "Summarizing long texts into shorter ones."
    },
    "answer": "B",
    "explanation": "Causality extraction is a complex NLP task that requires going beyond statistical patterns to infer underlying mechanisms, pushing the boundaries of what current deep learning models can do.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 195,
    "question": "How do 'Recurrent Convolutional Neural Networks (RCNNs)' combine the strengths of RNNs and CNNs?",
    "options": {
      "A": "They replace all convolutions with recurrent connections.",
      "B": "They combine convolutional layers for spatial feature extraction with recurrent layers (like LSTMs/GRUs) to model temporal dependencies, particularly useful for video analysis or structured document processing where both spatial and temporal patterns are relevant.",
      "C": "They only use recurrent layers for feature extraction.",
      "D": "They process images as sequences of pixels."
    },
    "answer": "B",
    "explanation": "RCNNs leverage the strengths of both architectures, allowing them to excel in tasks that involve both spatial patterns within frames/regions and temporal dynamics across sequences.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 196,
    "question": "What is the concept of 'Out-of-Distribution (OOD) Detection' in deep learning, and why is it crucial for real-world deployment?",
    "options": {
      "A": "Detecting outliers in the training data.",
      "B": "Identifying when a model is presented with input data that significantly differs from its training distribution, crucial because models often make overconfident and incorrect predictions on OOD data, impacting safety and reliability in critical applications.",
      "C": "Detecting models that are overfitting.",
      "D": "Detecting when a model's output is outside the expected range."
    },
    "answer": "B",
    "explanation": "OOD detection is vital for trustworthy AI, allowing systems to flag when they encounter data they are not well-equipped to handle, preventing potentially dangerous erroneous decisions.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 197,
    "question": "Explain the 'Gumbel-Softmax Trick' and its use in deep learning.",
    "options": {
      "A": "A trick to make softmax more stable.",
      "B": "A technique that allows for differentiable sampling from discrete distributions (like categorical variables) by approximating the argmax operation with a continuous, differentiable softmax, enabling end-to-end training of models with discrete latent variables.",
      "C": "A method to smooth out gradients in a network.",
      "D": "A way to generate more diverse samples from a continuous distribution."
    },
    "answer": "B",
    "explanation": "The Gumbel-Softmax trick is essential for training generative models that incorporate discrete latent variables, bridging the gap between discrete random variables and gradient-based optimization.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 198,
    "question": "What are 'Compositional Generalization' challenges in deep learning, and why are they hard to solve?",
    "options": {
      "A": "Generalizing to new combinations of familiar components, a challenge because deep models often learn superficial correlations rather than systematic, compositional rules, making them struggle with out-of-distribution compositions.",
      "B": "Generalizing across different datasets from the same domain.",
      "C": "The ability to generalize to unseen data that is very similar to training data.",
      "D": "Generalizing from images to text data."
    },
    "answer": "A",
    "explanation": "Compositional generalization (e.g., understanding 'red square' after seeing 'red circle' and 'blue square') is a benchmark for true intelligence and a major limitation of current deep learning models.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 199,
    "question": "How does 'Reinforcement Learning from Scratch' differ from 'Reinforcement Learning with Pre-trained Models' (e.g., in robotics)?",
    "options": {
      "A": "RL from scratch uses human demonstrations, while RL with pre-trained models does not.",
      "B": "RL from scratch involves training an agent from random initialization through direct interaction with the environment. RL with pre-trained models leverages features or policies learned by large pre-trained models (e.g., vision transformers) to provide a better starting point or more efficient exploration for the RL agent, reducing the need for vast interaction data.",
      "C": "RL from scratch is only for discrete action spaces.",
      "D": "RL with pre-trained models is less sample efficient."
    },
    "answer": "B",
    "explanation": "Leveraging pre-trained models in RL (e.g., using a Vision Transformer as a backbone) can significantly reduce the data and time needed to learn complex behaviors in rich environments.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 200,
    "question": "What is the theoretical maximum number of learnable parameters a neural network can have before encountering numerical instability?",
    "options": {
      "A": "There's no fixed theoretical maximum, as it depends on network architecture, data, and training setup.",
      "B": "Approximately 1 million parameters.",
      "C": "Exactly 1 billion parameters.",
      "D": "It's limited by the size of the input data."
    },
    "answer": "A",
    "explanation": "While practical limitations (memory, computational power) exist, and issues like vanishing/exploding gradients become more likely with more parameters and layers, there's no fixed theoretical limit to the number of parameters before numerical instability. Techniques like batch normalization, residual connections, and careful initialization help mitigate these issues, allowing for models with billions or even trillions of parameters.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 201,
    "question": "What is the primary objective of a 'Variational Autoencoder (VAE)' compared to a standard Autoencoder?",
    "options": {
      "A": "VAEs are only for classification, while Autoencoders are for regression.",
      "B": "VAEs learn a smooth, continuous, and probabilistic latent space from which new data can be generated by sampling, whereas standard Autoencoders learn a deterministic mapping for data compression.",
      "C": "VAEs do not use an encoder or decoder.",
      "D": "VAEs are less robust to noise than standard Autoencoders."
    },
    "answer": "B",
    "explanation": "VAEs' probabilistic approach to the latent space enables them to be used as generative models, unlike standard autoencoders which primarily focus on dimensionality reduction and reconstruction.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 202,
    "question": "Explain 'Knowledge Distillation' in the context of model deployment.",
    "options": {
      "A": "Training a large model on a small dataset.",
      "B": "Transferring knowledge from a large, complex 'teacher' model (trained for high accuracy) to a smaller, more efficient 'student' model, making the student model suitable for deployment on resource-constrained devices.",
      "C": "A method to extract the most important features from data.",
      "D": "Distributing the training of a model across multiple machines."
    },
    "answer": "B",
    "explanation": "Knowledge distillation allows for the creation of smaller, faster models that retain much of the performance of larger, more cumbersome models, which is crucial for edge computing or mobile deployment.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 203,
    "question": "What is the 'Attention Mechanism' primarily designed to overcome in traditional Sequence-to-Sequence models (RNN-based)?",
    "options": {
      "A": "The vanishing gradient problem in the encoder.",
      "B": "The limitation of encoding an entire input sequence into a single fixed-size context vector, which struggles with long sequences and loses information.",
      "C": "The exploding gradient problem in the decoder.",
      "D": "The need for a large amount of training data."
    },
    "answer": "B",
    "explanation": "Attention allows the decoder to dynamically refer back to different parts of the input sequence, providing more relevant context at each step of output generation, especially for long sequences.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 204,
    "question": "Discuss the 'Perceiver IO' architecture's solution to handling diverse high-dimensional inputs efficiently.",
    "options": {
      "A": "It converts all inputs into image format for CNN processing.",
      "B": "It uses a cross-attention mechanism to query a much smaller, fixed-size latent array from the high-dimensional input, allowing it to process arbitrary modalities and scales of input without quadratic complexity growth.",
      "C": "It reduces input dimensionality through simple linear compression.",
      "D": "It requires separate, specialized encoders for each input modality."
    },
    "answer": "B",
    "explanation": "Perceiver IO aims to provide a single, unified architecture for various data types (images, audio, text, video) by effectively bottlenecking the input information, addressing a major scaling challenge.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 205,
    "question": "What are 'Neural Radiance Fields (NeRFs)' fundamentally learning, and how does this enable novel view synthesis?",
    "options": {
      "A": "They learn a 2D image texture map.",
      "B": "They learn a continuous volumetric function that maps 3D coordinates (and viewing directions) to color and opacity values, which can then be ray-marched to render new, photorealistic views of a scene from any angle.",
      "C": "They learn to convert 3D point clouds into meshes.",
      "D": "They learn the lighting conditions of a scene."
    },
    "answer": "B",
    "explanation": "NeRFs represent a breakthrough in 3D scene representation and synthesis, allowing for highly realistic rendering of complex scenes by querying a neural network for properties at continuous points in space.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 206,
    "question": "Explain 'Active Learning' in deep learning and when it is most beneficial.",
    "options": {
      "A": "Training a model with all available data at once.",
      "B": "A machine learning paradigm where the learning algorithm can interactively query a user or another information source to label new data points, typically those it is most uncertain about, to efficiently improve model performance with minimal labeling cost.",
      "C": "Learning from continuously flowing data streams.",
      "D": "Actively adjusting hyperparameters during training."
    },
    "answer": "B",
    "explanation": "Active learning is particularly useful in scenarios where unlabeled data is abundant but labeling is expensive, allowing for more strategic and efficient data acquisition.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 207,
    "question": "What is 'Adversarial Training' in the context of improving model robustness, and what is its goal?",
    "options": {
      "A": "Training models to generate adversarial examples.",
      "B": "Training a model by exposing it to adversarial examples (inputs intentionally perturbed to fool the model) during the training phase, with the goal of making the model more resilient and less susceptible to such attacks during inference.",
      "C": "Training two models against each other to improve classification accuracy.",
      "D": "Training a model using only synthetic data."
    },
    "answer": "B",
    "explanation": "Adversarial training is a defense mechanism against adversarial attacks, aiming to improve the model's generalization and reliability on perturbed inputs.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 208,
    "question": "Describe 'Model Compression' techniques beyond pruning and quantization, such as 'Low-Rank Factorization' or 'Parameter Sharing'.",
    "options": {
      "A": "These techniques increase model size for better accuracy.",
      "B": "Low-rank factorization approximates large weight matrices with smaller matrices, reducing parameters. Parameter sharing forces different parameters to share the same value, reducing unique parameters. Both aim to reduce model size and computational cost for efficient deployment.",
      "C": "These techniques are primarily for improving training speed.",
      "D": "These methods are only applicable to very shallow networks."
    },
    "answer": "B",
    "explanation": "Model compression is crucial for deploying deep learning models on resource-constrained devices, allowing them to run efficiently while minimizing performance degradation.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 209,
    "question": "What is 'Equivariance' in neural networks, and how does it relate to 'Invariance'?",
    "options": {
      "A": "Equivariance means the output is unchanged by input transformations; invariance means the output transforms the same way as the input.",
      "B": "Invariance means the network's output remains the same despite an input transformation (e.g., classifying a rotated image as the same object). Equivariance means if the input is transformed, the output transforms in a *predictable* and *corresponding* way (e.g., rotating an input image rotates the output segmentation mask). Equivariance is often more powerful for structural tasks.",
      "C": "They are synonymous terms.",
      "D": "Equivariance is only for classification; invariance for regression."
    },
    "answer": "B",
    "explanation": "Equivariance is a stronger property than invariance and is desirable in tasks where the spatial relationship of features is important, like object detection or segmentation, where the output needs to change systematically with input transformations.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 210,
    "question": "How do 'Generative Flow Models' (or Normalizing Flows) work, and what is their advantage over GANs or VAEs?",
    "options": {
      "A": "They are a type of RNN for generating sequences.",
      "B": "They explicitly learn a series of invertible and differentiable transformations that map a simple base distribution (e.g., Gaussian) to the complex data distribution, allowing for exact likelihood computation and efficient sampling, unlike GANs or VAEs which often only provide approximate likelihoods.",
      "C": "They are used exclusively for anomaly detection.",
      "D": "They can only generate discrete data."
    },
    "answer": "B",
    "explanation": "Normalizing flows offer strong theoretical guarantees, exact likelihood estimation (useful for density estimation), and efficient inference, addressing some limitations of other generative models.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 211,
    "question": "Explain the concept of 'Curriculum Learning' in deep learning.",
    "options": {
      "A": "Training a model on randomly ordered data.",
      "B": "A training strategy where the model is first trained on 'easier' examples or tasks and gradually progresses to more complex ones, mimicking human learning and often leading to faster convergence and better generalization.",
      "C": "A method to constantly update the learning rate based on performance.",
      "D": "Learning different curricula for different models."
    },
    "answer": "B",
    "explanation": "Curriculum learning is a technique to guide the learning process in a structured way, which can be particularly beneficial for challenging tasks or when dealing with noisy data.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 212,
    "question": "What is 'Self-Supervised Learning' in the context of vision (e.g., SimCLR, MoCo) and how has it reduced reliance on labeled data?",
    "options": {
      "A": "Training models to classify images with human-provided labels.",
      "B": "It generates supervision from the data itself by creating 'pretext tasks' (e.g., predicting rotations, solving jigsaw puzzles, or contrasting augmented views of the same image), allowing powerful visual representations to be learned from large amounts of unlabeled data, which can then be fine-tuned for downstream tasks.",
      "C": "It uses pre-trained models exclusively for feature extraction.",
      "D": "It's a form of unsupervised clustering."
    },
    "answer": "B",
    "explanation": "Self-supervised learning has become incredibly important for computer vision, as it allows training on massive datasets without the prohibitive cost of human labeling, bridging the gap between supervised and unsupervised learning.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 213,
    "question": "Discuss the 'Compositional Generalization' problem in NLP, providing a concrete example.",
    "options": {
      "A": "The ability to generalize to longer sentences.",
      "B": "The challenge for models to correctly interpret or generate novel combinations of familiar words/concepts (e.g., understanding 'red truck' after seeing 'red car' and 'blue truck'), indicating a lack of true systematic generalization and reliance on surface-level correlations. Example: Learning a function that applies to 'jump' and 'left', but failing on 'jump left' if not seen directly.",
      "C": "Generalizing across different languages.",
      "D": "The difficulty in learning new vocabulary words."
    },
    "answer": "B",
    "explanation": "Compositional generalization is a critical hurdle for robust and truly intelligent NLP systems, as it requires moving beyond statistical associations to understand underlying rules.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 214,
    "question": "What is the 'Neural Tangent Kernel (NTK)' and its significance for understanding deep learning?",
    "options": {
      "A": "A new type of activation function for deep networks.",
      "B": "A mathematical object that describes the behavior of infinitely wide neural networks during training, showing that they behave like kernel methods and can be precisely characterized, providing theoretical insights into deep learning's generalization capabilities.",
      "C": "A technique for visualizing the inner workings of neurons.",
      "D": "A method for designing optimal network architectures."
    },
    "answer": "B",
    "explanation": "NTK theory offers a powerful lens through which to understand the optimization and generalization properties of overparameterized neural networks in the infinite-width limit.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 215,
    "question": "How does 'Reinforcement Learning from Human Feedback (RLHF)' fundamentally differ from standard Supervised Learning in aligning large language models?",
    "options": {
      "A": "RLHF uses larger datasets for training.",
      "B": "Supervised learning trains models on fixed datasets of correct input-output pairs. RLHF trains a reward model from human preference comparisons, and then uses RL to fine-tune the language model to maximize this learned reward, allowing for more nuanced alignment with human values that are hard to capture with explicit labels.",
      "C": "RLHF is faster to train than supervised learning.",
      "D": "RLHF does not require any human input."
    },
    "answer": "B",
    "explanation": "RLHF is a key innovation for making large models useful and safe by translating subjective human preferences into an objective function for optimization.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 216,
    "question": "What is the 'Gumbel-Softmax Trick' used for, and why is it important for training models with discrete latent variables?",
    "options": {
      "A": "To make continuous variables discrete.",
      "B": "It provides a differentiable approximation of sampling from a discrete categorical distribution, allowing gradient-based optimization to flow through discrete choices within a neural network (e.g., in VAEs for discrete data or in text generation).",
      "C": "To create a sharper probability distribution.",
      "D": "To ensure that all discrete variables are positive."
    },
    "answer": "B",
    "explanation": "This trick is essential for enabling end-to-end training of models that involve discrete components, which are otherwise non-differentiable.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 217,
    "question": "Explain 'Meta-Learning for Optimization' (e.g., learned optimizers).",
    "options": {
      "A": "Optimizing hyperparameters using manual trial-and-error.",
      "B": "Training a neural network (the 'meta-optimizer') to learn how to update the parameters of another neural network (the 'learner' or 'base' model), aiming to discover more efficient and robust optimization algorithms than hand-designed ones.",
      "C": "Applying a single optimizer to multiple deep learning models.",
      "D": "Optimizing the entire training process on a single, fixed dataset."
    },
    "answer": "B",
    "explanation": "Learned optimizers explore the idea of having AI design better AI, potentially leading to faster training and better generalization across various tasks.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 218,
    "question": "What is a 'Mixture of Experts (MoE)' model's main architectural characteristic and advantage?",
    "options": {
      "A": "All input is processed by all experts simultaneously.",
      "B": "It consists of multiple 'expert' sub-networks and a 'gating network' that learns to selectively activate only a few relevant experts for each input, allowing for vast model capacity with sparse activation and efficient inference compared to a dense model of similar capacity.",
      "C": "It uses a single, very powerful expert for all tasks.",
      "D": "It combines predictions from multiple pre-trained models."
    },
    "answer": "B",
    "explanation": "MoEs are key to scaling large language models to unprecedented sizes while maintaining reasonable training and inference costs.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 219,
    "question": "How does 'Implicit Neural Representations (INRs)' differ from traditional discrete representations (e.g., pixels, voxels) for modeling signals?",
    "options": {
      "A": "INRs are only used for 2D images.",
      "B": "INRs represent signals (images, 3D shapes, audio) as continuous functions parameterized by a neural network, where coordinates are input and signal values are output. This allows for continuous resolution, efficient storage, and smooth interpolation, unlike discrete grids.",
      "C": "INRs require much more storage space.",
      "D": "INRs are always faster to render."
    },
    "answer": "B",
    "explanation": "INRs (e.g., NeRFs for 3D scenes) are a powerful paradigm shift for representing and generating continuous signals, offering advantages in terms of memory, resolution, and generalization.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 220,
    "question": "What is 'Adversarial Machine Learning' and what are its three main categories of attacks?",
    "options": {
      "A": "Learning a game strategy against a human player; the categories are chess, Go, and StarCraft.",
      "B": "A field focused on the security and robustness of ML models against malicious inputs; the three main categories of attacks are Evasion Attacks (during inference), Poisoning Attacks (during training), and Model Inversion/Extraction Attacks (to steal information about the model or its training data).",
      "C": "Machine learning that involves adversarial networks for generative tasks; the categories are GANs, VAEs, and Normalizing Flows.",
      "D": "A type of reinforcement learning where two agents compete; the categories are competitive, cooperative, and mixed."
    },
    "answer": "B",
    "explanation": "Understanding and defending against these attack vectors is paramount for deploying deep learning models in sensitive applications where reliability and security are critical.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 221,
    "question": "Discuss the 'Information Bottleneck Principle' in deep learning.",
    "options": {
      "A": "It states that networks should retain all information from the input.",
      "B": "It suggests that optimal representations should compress irrelevant information from the input while preserving as much relevant information about the target variable as possible, potentially explaining why deep networks learn hierarchical and disentangled features.",
      "C": "It's a principle for preventing vanishing gradients.",
      "D": "It claims that adding more layers always improves information flow."
    },
    "answer": "B",
    "explanation": "The Information Bottleneck Principle provides a theoretical framework for understanding how deep networks learn by extracting compact and relevant representations of data.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 222,
    "question": "What are 'Diffusion Probabilistic Models' (DDPMs) and their core idea for generation?",
    "options": {
      "A": "Models that generate text by diffusing word embeddings.",
      "B": "Generative models that define a forward process of progressively adding Gaussian noise to data, and then learn a neural network to reverse this noisy process, iteratively denoising a random noise sample into a clean data sample (e.g., an image).",
      "C": "Models that diffuse gradients across layers.",
      "D": "Models that predict the probability of diffusion in a material."
    },
    "answer": "B",
    "explanation": "DDPMs are a class of powerful generative models that have achieved state-of-the-art results in image and audio synthesis due to their ability to model complex data distributions through a gradual denoising process.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 223,
    "question": "How do 'Neuro-Evolutionary Algorithms' (NEAs) like NEAT combine neural networks and evolutionary computation?",
    "options": {
      "A": "They use neural networks to predict evolutionary paths.",
      "B": "NEAs use evolutionary algorithms to optimize the weights and/or architecture of neural networks, rather than gradient-based methods, useful for tasks where gradients are hard to obtain (e.g., RL) or for exploring novel architectures.",
      "C": "They are a type of recurrent neural network for genetic data.",
      "D": "They use neural networks to simulate biological evolution."
    },
    "answer": "B",
    "explanation": "NEAs offer an alternative optimization paradigm that can explore a wider range of solutions and are well-suited for black-box optimization problems.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 224,
    "question": "What is the 'Simulated Annealing' algorithm, and how can it be used in deep learning?",
    "options": {
      "A": "A method for training very large neural networks quickly.",
      "B": "A metaheuristic optimization algorithm inspired by annealing in metallurgy, used to find good approximations to the global optimum of a given function (e.g., for hyperparameter optimization or sampling from complex energy landscapes in deep generative models).",
      "C": "A type of activation function that mimics material properties.",
      "D": "A data augmentation technique for image rotation."
    },
    "answer": "B",
    "explanation": "Simulated Annealing is a powerful technique for searching complex spaces and can be applied in various deep learning contexts where standard gradient descent is insufficient.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 225,
    "question": "Explain 'Zero-Shot Learning' in the context of computer vision.",
    "options": {
      "A": "Classifying images into categories already seen during training.",
      "B": "The ability of a model to classify images belonging to classes that were not present in the training data, often achieved by leveraging semantic side information (e.g., attributes of categories, word embeddings of class names).",
      "C": "Generating images without any input data.",
      "D": "Learning from a single training example per class."
    },
    "answer": "B",
    "explanation": "Zero-shot learning is crucial for building AI systems that can adapt to new concepts without requiring extensive re-training and data collection for every new category.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 226,
    "question": "What is the concept of 'Domain Adaptation' in deep learning, and why is it important?",
    "options": {
      "A": "Adapting a model to a new programming language.",
      "B": "The process of adapting a model trained on a source domain (dataset) to perform well on a different, but related, target domain (dataset) where labeled data might be scarce or unavailable, crucial for deploying models in real-world scenarios with distribution shifts.",
      "C": "Adapting the model's architecture to new tasks.",
      "D": "Adapting the learning rate dynamically during training."
    },
    "answer": "B",
    "explanation": "Domain adaptation addresses the challenge of models performing poorly when tested on data from a different distribution than their training data, common in real-world deployments.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 227,
    "question": "How do 'Deep Reinforcement Learning' algorithms differ from traditional RL algorithms?",
    "options": {
      "A": "They only use policy iteration.",
      "B": "Deep RL uses deep neural networks as function approximators for policies, value functions, or Q-functions, allowing them to handle high-dimensional state and action spaces (e.g., pixels from a game screen) that traditional RL struggles with, enabling learning complex behaviors from raw sensory input.",
      "C": "Deep RL does not use reward signals.",
      "D": "Deep RL is only for discrete action spaces."
    },
    "answer": "B",
    "explanation": "The integration of deep learning with reinforcement learning (e.g., Deep Q-Networks for Atari games) has enabled significant breakthroughs in learning complex control policies directly from raw observations.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 228,
    "question": "What is the 'Energy-Based Model (EBM)' framework in deep learning?",
    "options": {
      "A": "Models that learn to predict energy consumption.",
      "B": "A generative modeling framework that defines an energy function, typically a neural network, where lower energy corresponds to higher probability data samples, and learning involves shaping this energy landscape to match the data distribution.",
      "C": "Models used to simulate energy flow in physical systems.",
      "D": "Models that minimize energy during training."
    },
    "answer": "B",
    "explanation": "EBMs offer an alternative to GANs and VAEs, providing a unified framework for both generative and discriminative tasks by learning a scalar energy function.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 229,
    "question": "Explain 'Pruning' in the context of neural network efficiency, and why 'magnitude pruning' might not always be optimal.",
    "options": {
      "A": "Pruning adds more neurons; magnitude pruning adds neurons based on activation strength.",
      "B": "Pruning removes weights/neurons to reduce model size/computational cost. Magnitude pruning removes weights with the smallest absolute values, which is simple but not always optimal because low-magnitude weights can still be critical for network performance or because the 'importance' of a weight is not solely determined by its magnitude.",
      "C": "Pruning is only for LSTMs; magnitude pruning is for CNNs.",
      "D": "Pruning increases the model's robustness to noise."
    },
    "answer": "B",
    "explanation": "While simple, magnitude pruning often leads to sub-optimal results, prompting research into more sophisticated pruning criteria like sensitivity-based or gradient-based pruning.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 230,
    "question": "How does 'Graph Convolutional Network (GCN)' extend the idea of convolution to irregular graph data?",
    "options": {
      "A": "GCNs convert graphs into images for CNN processing.",
      "B": "GCNs define a form of convolution that operates on graph structures by aggregating information from a node's local neighborhood (its direct connections) and transforming it, effectively learning node representations that incorporate both features and graph topology.",
      "C": "GCNs only work on perfectly regular grid-like graphs.",
      "D": "GCNs remove all edges from a graph before processing."
    },
    "answer": "B",
    "explanation": "GCNs are fundamental building blocks of many GNN architectures, enabling deep learning on non-Euclidean data like social networks, molecular structures, and citation graphs.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 231,
    "question": "What is 'Self-Supervised Learning' in audio processing (e.g., wav2vec 2.0), and why is it important?",
    "options": {
      "A": "Training audio models with labeled speech data.",
      "B": "It pre-trains audio models on large amounts of unlabeled audio data by defining proxy tasks (e.g., predicting masked speech segments or contrasting positive/negative samples), allowing the model to learn rich, generalized audio representations that can then be fine-tuned for specific downstream tasks like speech recognition with less labeled data.",
      "C": "It uses pre-trained text models for audio tasks.",
      "D": "It's a form of audio compression without data loss."
    },
    "answer": "B",
    "explanation": "Self-supervised learning has revolutionized audio processing by reducing the heavy reliance on massive, manually transcribed speech datasets, making state-of-the-art models more accessible.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 232,
    "question": "How does 'Reinforcement Learning from Human Feedback (RLHF)' help to align large language models with user intent and values?",
    "options": {
      "A": "It directly hardcodes human values into the model's parameters.",
      "B": "By training a separate 'reward model' on human preference comparisons (e.g., which generated response is better), and then using this learned reward model to fine-tune the language model via reinforcement learning, guiding it to produce responses that are helpful, harmless, and honest.",
      "C": "It requires the model to explain its reasoning in human language.",
      "D": "It limits the model's ability to generate creative text."
    },
    "answer": "B",
    "explanation": "RLHF is a crucial step in developing safe and helpful AI, moving beyond simply predicting the next word to generating content that aligns with complex human preferences.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 233,
    "question": "What are 'Latent Diffusion Models (LDMs)' and how do they address the computational cost of direct pixel-space diffusion models?",
    "options": {
      "A": "LDMs operate on compressed image formats like JPEGs.",
      "B": "LDMs perform the iterative denoising process in a lower-dimensional latent space learned by an autoencoder, significantly reducing the computational and memory requirements compared to diffusing directly in high-dimensional pixel space, while maintaining high visual quality.",
      "C": "LDMs use a simpler neural network architecture for generation.",
      "D": "LDMs only generate low-resolution images."
    },
    "answer": "B",
    "explanation": "LDMs (e.g., Stable Diffusion) make high-resolution image generation from diffusion models much more practical and accessible by working in a more compact latent representation.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 234,
    "question": "Explain the concept of 'Energy-Based Models (EBMs)' for deep generative learning, and their relationship to probabilistic graphical models.",
    "options": {
      "A": "EBMs are a type of recurrent neural network.",
      "B": "EBMs define a scalar energy function (parameterized by a neural network) that assigns low energy to typical data and high energy to atypical data. The probability of data is inversely proportional to its energy. They offer a general framework that can encompass and generalize various probabilistic graphical models by learning the relationships between variables through an energy landscape.",
      "C": "EBMs are only used for unsupervised clustering.",
      "D": "EBMs are a simpler form of GANs."
    },
    "answer": "B",
    "explanation": "EBMs offer a flexible and powerful generative framework that can be applied to both discrete and continuous data, and their connection to statistical physics provides rich theoretical underpinnings.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 235,
    "question": "How does 'Neural Architecture Search (NAS)' contribute to the field of deep learning?",
    "options": {
      "A": "It manually optimizes neural network hyperparameters.",
      "B": "NAS automates the design of neural network architectures, enabling the discovery of novel and often superior architectures compared to manually designed ones, leading to improved performance and efficiency for specific tasks.",
      "C": "NAS is primarily used for dataset curation.",
      "D": "NAS only suggests optimal learning rates."
    },
    "answer": "B",
    "explanation": "NAS aims to democratize and accelerate the process of finding high-performing neural network architectures, moving beyond reliance on expert intuition.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 236,
    "question": "What is the 'Double Descent' phenomenon in deep learning, and why is it counter-intuitive from a classical bias-variance trade-off perspective?",
    "options": {
      "A": "It refers to the model performing well on both training and test data simultaneously.",
      "B": "It's the observation that model performance (test error) first decreases, then increases (classical overfitting regime), and then decreases again as model capacity (or training time) increases, even past the point of interpolating the training data. This contradicts the traditional U-shaped bias-variance curve, suggesting that extremely overparameterized models can generalize well.",
      "C": "It describes a model's loss oscillating between two values.",
      "D": "It's a problem unique to very shallow neural networks."
    },
    "answer": "B",
    "explanation": "Double descent challenges long-held beliefs about model complexity and generalization, opening new avenues for theoretical understanding of deep learning.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 237,
    "question": "Explain 'Sparse Attention' mechanisms and their motivation in large Transformer models.",
    "options": {
      "A": "Sparse attention means fewer attention heads are used.",
      "B": "Instead of computing attention weights between every pair of tokens (which is quadratically expensive for long sequences), sparse attention mechanisms restrict attention to a local window or a few 'global' tokens, significantly reducing computational complexity and memory usage for very long sequences.",
      "C": "Sparse attention encourages all attention weights to be exactly zero.",
      "D": "Sparse attention is only for short sequences."
    },
    "answer": "B",
    "explanation": "Sparse attention is crucial for scaling Transformer models to process extremely long sequences (e.g., entire documents or long audio clips) without incurring prohibitive computational costs.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 238,
    "question": "What is 'Continual Learning' (or Lifelong Learning) and what is the 'catastrophic forgetting' problem it aims to solve?",
    "options": {
      "A": "Learning to remember only past mistakes.",
      "B": "Continual learning is the ability of an AI system to continuously learn new tasks and adapt to new data without forgetting previously acquired knowledge. Catastrophic forgetting is the phenomenon where a neural network rapidly loses performance on previously learned tasks when trained on new tasks, which continual learning aims to mitigate.",
      "C": "Learning only one task at a time, sequentially.",
      "D": "A method to deliberately forget old information."
    },
    "answer": "B",
    "explanation": "Addressing catastrophic forgetting is a key challenge for developing truly intelligent and adaptable AI agents that can learn incrementally in dynamic environments.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 239,
    "question": "How do 'Hypernetworks' allow for more flexible and adaptive deep learning models?",
    "options": {
      "A": "They increase the number of layers in a fixed network.",
      "B": "By having one neural network (the hypernetwork) generate the weights or architecture of another neural network (the main network), they enable the main network's parameters to be dynamically conditioned on an input (e.g., a task, a style code), leading to more adaptive models, especially for meta-learning and few-shot learning.",
      "C": "They are a type of ensemble model where multiple networks are trained independently.",
      "D": "They only learn to tune hyperparameters automatically."
    },
    "answer": "B",
    "explanation": "Hypernetworks represent a powerful approach to creating context-dependent or task-specific neural networks without requiring a full retraining for each new context.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 240,
    "question": "Explain the concept of 'Compositional Generalization' in terms of symbol manipulation in deep learning.",
    "options": {
      "A": "The ability to generalize to unseen data that is very similar to training data.",
      "B": "The capacity of a model to combine known concepts (symbols) in novel ways to understand or generate new, unseen compositions. This requires systematic reasoning and rule-learning, which is challenging for deep learning models that often rely on statistical correlations rather than explicit symbolic manipulation.",
      "C": "Generalizing across different domains with different data distributions.",
      "D": "Learning new concepts by seeing only one example."
    },
    "answer": "B",
    "explanation": "This is a key frontier in AI, as it touches upon the ability of models to truly understand and reason, rather than just interpolate from training data.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 241,
    "question": "What is the 'Neural Tangent Kernel (NTK)' and its implications for understanding the learning dynamics of wide neural networks?",
    "options": {
      "A": "NTK describes the behavior of infinitely deep neural networks.",
      "B": "NTK is a kernel that emerges in the infinite-width limit of neural networks trained with gradient descent, implying that such wide networks behave like kernel methods. This provides a theoretical framework to analyze their optimization and generalization properties without considering their deep, non-linear nature explicitly.",
      "C": "NTK is an activation function for convolutional networks.",
      "D": "NTK is a method to find optimal initializations for narrow networks."
    },
    "answer": "B",
    "explanation": "The NTK theory offers a simplified, yet powerful, lens to analyze the behavior of very wide deep learning models, particularly regarding their training dynamics and generalization capabilities in a linearizable regime.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 242,
    "question": "How do 'Spiking Neural Networks (SNNs)' represent and process information differently from Artificial Neural Networks (ANNs)?",
    "options": {
      "A": "SNNs use continuous activation values and static connections.",
      "B": "SNNs encode information in the timing and frequency of discrete 'spikes' (events) and operate asynchronously, mimicking biological neural systems more closely. ANNs use continuous activation values and typically process information synchronously in layers.",
      "C": "SNNs are only used for supervised learning tasks.",
      "D": "SNNs are computationally more intensive on standard hardware."
    },
    "answer": "B",
    "explanation": "SNNs are a promising area of research for energy-efficient AI and neuromorphic computing, leveraging the sparse and event-driven nature of biological neural communication.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 243,
    "question": "What is the key idea behind 'Neural Ordinary Differential Equations (NODEs)'?",
    "options": {
      "A": "NODEs replace activation functions with differential equations.",
      "B": "NODEs model the transformation of hidden states in a neural network as a continuous dynamical system governed by an Ordinary Differential Equation (ODE), parameterized by a neural network. This allows for arbitrary depth and memory-efficient backpropagation through an adjoint method.",
      "C": "NODEs are a type of recurrent network for solving differential equations.",
      "D": "NODEs are a method for solving partial differential equations only."
    },
    "answer": "B",
    "explanation": "NODEs provide a novel way to conceptualize and build neural networks, offering advantages in terms of memory footprint, handling irregular time series, and interpretability through continuous dynamics.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 244,
    "question": "How does 'Optimal Transport' relate to 'Wasserstein GANs' (WGANs) and improve their training stability?",
    "options": {
      "A": "Optimal Transport is a form of regularization for GANs.",
      "B": "Optimal Transport provides the theoretical foundation for the Earth Mover's Distance (or Wasserstein distance), which WGANs use as a loss function instead of Jensen-Shannon divergence. This distance metric is smoother and differentiable almost everywhere, offering more stable gradients and avoiding mode collapse issues often seen in traditional GANs.",
      "C": "Optimal Transport is used to generate more diverse samples.",
      "D": "Optimal Transport helps to reduce the dimensionality of the latent space."
    },
    "answer": "B",
    "explanation": "The Earth Mover's Distance offers a more robust measure of dissimilarity between distributions, leading to more reliable training and higher-quality generated samples in WGANs.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 245,
    "question": "What are 'Compositional Generalization' challenges in Deep Learning and why are they difficult?",
    "options": {
      "A": "The ability to create complex compositions of images.",
      "B": "The failure of models to systematically generalize to new combinations of familiar components (e.g., 'red square' from 'red circle' and 'blue square'). This is hard because deep learning often learns correlations rather than explicit symbolic rules, struggling to combine learned concepts in novel ways.",
      "C": "The difficulty of combining different deep learning architectures.",
      "D": "Generalizing from small datasets to larger ones."
    },
    "answer": "B",
    "explanation": "This is a key area of research aiming to bridge the gap between statistical learning and symbolic reasoning, vital for building AI that can truly understand and reason about the world.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 246,
    "question": "Explain the concept of 'Domain Generalization' and how it differs from 'Domain Adaptation'.",
    "options": {
      "A": "Domain Generalization requires labeled target data; Domain Adaptation does not.",
      "B": "Domain Adaptation adapts a model to a *known* target domain with *some* labeled or unlabeled target data. Domain Generalization aims to train a model on one or more source domains such that it can directly perform well on *unseen* target domains without any access to target domain data during training, making it a much harder problem.",
      "C": "Domain Generalization is for classification; Domain Adaptation for regression.",
      "D": "They are synonymous terms for the same problem."
    },
    "answer": "B",
    "explanation": "Domain Generalization is a more challenging and impactful problem for real-world AI deployment, as it aims for models that are robust to unexpected shifts in data distribution.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 247,
    "question": "What is 'Adversarial Machine Learning' more broadly, encompassing both attacks and defenses?",
    "options": {
      "A": "Machine learning focused on ethical dilemmas.",
      "B": "The study of designing machine learning systems that are robust to malicious attacks (evasion, poisoning, inference) and also designing attacks to probe the vulnerabilities of these systems, aiming to build more secure and reliable AI.",
      "C": "A subfield of reinforcement learning where agents compete.",
      "D": "Using machine learning to predict adversarial outcomes in games."
    },
    "answer": "B",
    "explanation": "This field is crucial for the secure deployment of AI in sensitive applications like self-driving cars, medical diagnosis, and financial systems.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 248,
    "question": "How do 'Implicit Neural Representations (INRs)' offer advantages over traditional grid-based representations for 3D data?",
    "options": {
      "A": "INRs only work with low-resolution 3D data.",
      "B": "INRs represent 3D objects or scenes as continuous functions mapped by neural networks, allowing for arbitrary resolution query, compact storage, and efficient differentiation, overcoming the memory and discretization limitations of discrete voxel grids or meshes.",
      "C": "INRs are much slower for rendering 3D scenes.",
      "D": "INRs can only represent simple geometric shapes."
    },
    "answer": "B",
    "explanation": "INRs (like NeRFs) are revolutionizing 3D computer vision and graphics by enabling highly detailed and continuous representations of complex scenes from sparse inputs.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 249,
    "question": "What is 'Model Quantization' and its impact on hardware deployment of deep learning models?",
    "options": {
      "A": "It increases the floating-point precision of weights for better accuracy.",
      "B": "It reduces the number of bits used to represent weights and activations (e.g., from 32-bit floats to 8-bit integers), drastically shrinking model size, reducing memory bandwidth, and enabling faster inference on specialized hardware (e.g., edge devices, mobile GPUs) with lower power consumption.",
      "C": "It quantifies the model's uncertainty in its predictions.",
      "D": "It's a technique to make models more interpretable."
    },
    "answer": "B",
    "explanation": "Quantization is a critical optimization technique for deploying large deep learning models in real-world scenarios, especially on resource-constrained platforms.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 250,
    "question": "Explain 'Meta-Learning' (Learning to Learn) and its application in 'Few-Shot Learning'.",
    "options": {
      "A": "Meta-learning trains a single model on a huge dataset.",
      "B": "Meta-learning trains a model (the meta-learner) to acquire a general learning ability (e.g., how to initialize weights or how to adapt an optimizer) across a distribution of tasks. In few-shot learning, the meta-learner uses this acquired ability to quickly learn a new task from very few examples, by leveraging knowledge gained from similar past tasks.",
      "C": "Meta-learning is only for reinforcement learning.",
      "D": "Meta-learning focuses on increasing the training data size."
    },
    "answer": "B",
    "explanation": "Meta-learning for few-shot learning aims to make models more data-efficient and adaptable to novel tasks, bridging the gap between current data-hungry deep learning and human-like rapid learning.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 251,
    "question": "How does 'Bayesian Neural Networks (BNNs)' provide uncertainty quantification compared to standard neural networks?",
    "options": {
      "A": "BNNs only output a single point prediction like standard ANNs.",
      "B": "Standard ANNs output point estimates for predictions and weights, providing no explicit uncertainty. BNNs model probability distributions over weights, propagating this uncertainty through the network to yield a predictive distribution (e.g., mean and variance) for outputs, giving a measure of confidence in predictions.",
      "C": "BNNs use a specific activation function that quantifies uncertainty.",
      "D": "BNNs predict only the uncertainty, not the actual value."
    },
    "answer": "B",
    "explanation": "Uncertainty quantification is vital for high-stakes applications where knowing 'what the model doesn't know' is as important as its prediction.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 252,
    "question": "What are 'Graph Attention Networks (GATs)' and how do they enhance GCNs?",
    "options": {
      "A": "GATs remove the need for graph structure.",
      "B": "GATs introduce an attention mechanism to graph convolutional layers, allowing each node to learn varying importance weights for its neighbors during feature aggregation, rather than using fixed or pre-defined weights. This enables the model to focus on more relevant neighbors and provides improved expressiveness.",
      "C": "GATs are a type of recurrent neural network for graphs.",
      "D": "GATs simplify the message-passing mechanism in graphs."
    },
    "answer": "B",
    "explanation": "GATs allow for more flexible and powerful graph learning by adaptively weighting neighbor contributions, leading to better performance on complex graph tasks.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 253,
    "question": "Explain 'Mixture Density Networks (MDNs)' and when they are a better choice for regression problems.",
    "options": {
      "A": "MDNs are used when the output is always a single, fixed value.",
      "B": "MDNs output the parameters (means, variances, and mixing coefficients) of a mixture of probability distributions, rather than a single point estimate. They are better when the relationship between input and output is multimodal, or when the output inherently has uncertainty, allowing the model to capture the full conditional probability distribution.",
      "C": "MDNs are only for classification problems with many classes.",
      "D": "MDNs only work with linear regression models."
    },
    "answer": "B",
    "explanation": "MDNs provide a richer understanding of the underlying relationship by modeling multiple possible outputs and their probabilities, suitable for complex and uncertain regression tasks.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 254,
    "question": "What is the primary challenge in 'Online Learning' for deep neural networks, and how can it be addressed?",
    "options": {
      "A": "The lack of sufficient computational power.",
      "B": "The 'catastrophic forgetting' problem, where a model trained continuously on sequential data forgets previously learned knowledge as new data arrives. It can be addressed by techniques like 'elastic weight consolidation' (EWC), 'synaptic intelligence', or 'replay buffers'.",
      "C": "The difficulty of obtaining labels for streaming data.",
      "D": "The inability to use gradient descent in an online setting."
    },
    "answer": "B",
    "explanation": "Online learning is crucial for systems that need to continuously adapt in dynamic environments, and mitigating catastrophic forgetting is a key area of research.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 255,
    "question": "How do 'Deep Reinforcement Learning' algorithms handle high-dimensional observation spaces (e.g., raw pixel data)?",
    "options": {
      "A": "By manually engineering features from the pixel data.",
      "B": "By using deep neural networks (e.g., CNNs) as function approximators to learn rich, low-dimensional representations directly from raw pixels, overcoming the 'curse of dimensionality' that traditional RL methods face with large state spaces.",
      "C": "By converting pixel data into symbolic representations.",
      "D": "By ignoring most of the pixel information."
    },
    "answer": "B",
    "explanation": "The ability of deep networks to learn effective representations from raw sensory input is what enabled breakthroughs in deep RL, allowing agents to play Atari games or control robotic systems directly from pixels.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 256,
    "question": "What is 'Causal Inference' in the context of deep learning, and why is it gaining importance?",
    "options": {
      "A": "Inferring the cause of training errors.",
      "B": "The study of determining cause-and-effect relationships from data, rather than just correlations. It's important because it leads to more robust, generalizable, and interpretable AI systems that can reason about interventions and make better decisions, especially under distribution shifts.",
      "C": "Inferring the initial conditions of a neural network.",
      "D": "It's a method for optimizing the learning rate."
    },
    "answer": "B",
    "explanation": "Integrating causal reasoning into deep learning is a frontier aimed at moving AI beyond pattern recognition to deeper understanding and true intelligence.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 257,
    "question": "Explain 'Generative Flow Models' (Normalizing Flows) and their unique property of exact likelihood computation.",
    "options": {
      "A": "Flow models are used to generate discrete data only.",
      "B": "Flow models construct complex probability distributions by applying a sequence of invertible and differentiable transformations to a simple base distribution (e.g., Gaussian). This invertibility allows for exact and efficient computation of the likelihood (probability density) of any data point, unlike GANs or VAEs which typically provide only approximate likelihoods.",
      "C": "Flow models require significantly more data than GANs.",
      "D": "Flow models are primarily for classification tasks."
    },
    "answer": "B",
    "explanation": "The ability to compute exact likelihoods is a significant advantage of normalizing flows, making them valuable for tasks like density estimation, anomaly detection, and data compression.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 258,
    "question": "What is 'Neuro-Symbolic AI' and why is it proposed as a way to address limitations of pure deep learning?",
    "options": {
      "A": "It merges neuroscience with AI to build brain-like models.",
      "B": "It combines the strengths of connectionist (deep learning) models, which excel at pattern recognition and learning from data, with symbolic AI (e.g., logic, rules, knowledge graphs), which excel at reasoning, planning, and explainability. This aims to create AI systems that are more robust, interpretable, and generalizable.",
      "C": "It is a method to visualize neural network activations as symbols.",
      "D": "It removes all neural network components and relies solely on symbolic logic."
    },
    "answer": "B",
    "explanation": "Neuro-symbolic AI seeks to combine the best of both worlds, addressing deep learning's black-box nature and difficulty with systematic reasoning.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 259,
    "question": "What is the 'Neural Radiance Field (NeRF)' technique, and what is its primary contribution to 3D scene representation?",
    "options": {
      "A": "It creates 3D meshes directly from 2D images.",
      "B": "NeRF models a 3D scene as a continuous volumetric function, parameterized by a small multi-layer perceptron (MLP). This function maps 3D coordinates and viewing directions to a predicted color and volume density, enabling the synthesis of novel photorealistic views of complex scenes from a sparse set of input images.",
      "C": "It's a new loss function for 3D object detection.",
      "D": "It's a method for compressing 3D models efficiently."
    },
    "answer": "B",
    "explanation": "NeRFs have set a new standard for novel view synthesis and 3D scene representation, moving beyond traditional mesh or voxel-based approaches.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 260,
    "question": "How do 'Deep Reinforcement Learning' agents learn complex behaviors from raw sensory inputs (e.g., pixels from video games)?",
    "options": {
      "A": "They rely on manual feature engineering from pixels.",
      "B": "They use deep neural networks (like CNNs or MLPs) as function approximators to learn rich, abstract representations directly from high-dimensional raw sensory inputs, and then use these representations to approximate optimal policies or value functions, allowing them to learn complex control strategies end-to-end.",
      "C": "They convert pixels into symbolic states before learning.",
      "D": "They only work with pre-defined, low-dimensional state spaces."
    },
    "answer": "B",
    "explanation": "The combination of deep learning's representation power with reinforcement learning's goal-directed learning has led to AI agents capable of superhuman performance in complex environments.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 261,
    "question": "What is the 'curse of dimensionality' in high-dimensional data, and how do deep neural networks intrinsically address it?",
    "options": {
      "A": "It means deep networks are harder to train in high dimensions.",
      "B": "The 'curse of dimensionality' refers to the exponential growth of data requirements and sparsity as dimensionality increases. Deep neural networks implicitly mitigate this by learning hierarchical, low-dimensional, and often disentangled feature representations (manifold learning), effectively 'flattening' the high-dimensional data onto a lower-dimensional manifold where learning is easier.",
      "C": "Deep networks increase the dimensionality of data.",
      "D": "It's a problem only for shallow models, not deep ones."
    },
    "answer": "B",
    "explanation": "Deep learning's ability to discover underlying low-dimensional structures from complex high-dimensional data is a key reason for its success.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 262,
    "question": "Explain 'Attention Is All You Need' and its foundational impact on NLP model design.",
    "options": {
      "A": "It proved that only convolution is needed for NLP.",
      "B": "This seminal paper introduced the Transformer architecture, demonstrating that self-attention mechanisms alone, without recurrence (RNNs) or convolutions (CNNs), could achieve state-of-the-art results in sequence modeling tasks like machine translation. This enabled unprecedented parallelization during training and superior handling of long-range dependencies, becoming the bedrock of modern large language models.",
      "C": "It argued that only the input and output layers are necessary.",
      "D": "It focused on reducing the number of parameters in sequence models."
    },
    "answer": "B",
    "explanation": "The Transformer's reliance on attention fundamentally changed how sequential data is processed, leading to the rise of powerful pre-trained models like BERT and GPT.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 263,
    "question": "What is 'Model Distillation' and how does it relate to 'Knowledge Distillation'?",
    "options": {
      "A": "Model Distillation is a subset of Knowledge Distillation where only the model's architecture is changed.",
      "B": "Model Distillation is a broader term encompassing various techniques to reduce model complexity. Knowledge Distillation is a specific form of model distillation where a small 'student' model learns from the 'soft targets' (probability distributions) of a larger, pre-trained 'teacher' model, transferring the teacher's nuanced knowledge.",
      "C": "Model Distillation is only for pruning; Knowledge Distillation for quantization.",
      "D": "They are unrelated concepts."
    },
    "answer": "B",
    "explanation": "Knowledge Distillation is a highly effective method within the broader field of model distillation, focusing on transferring 'dark knowledge' from a teacher to a student.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 264,
    "question": "How does 'Reinforcement Learning from Human Feedback (RLHF)' help in aligning Large Language Models (LLMs) with human values and safety constraints?",
    "options": {
      "A": "By programming explicit rules for ethical behavior into the LLM.",
      "B": "RLHF uses human preferences on LLM outputs to train a 'reward model'. This reward model then serves as the objective function for fine-tuning the LLM through reinforcement learning, guiding the LLM to generate responses that are preferred by humans (e.g., helpful, honest, harmless) even when explicit rules are difficult to define.",
      "C": "By having humans manually edit all of the LLM's generated text.",
      "D": "By removing all biases from the LLM's training data."
    },
    "answer": "B",
    "explanation": "RLHF is critical for creating LLMs that are not just performant but also safe, ethical, and user-aligned, addressing the challenge of aligning powerful generative AI with complex human intentions.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 265,
    "question": "Explain 'Zero-Shot Learning' in the context of Natural Language Processing (NLP).",
    "options": {
      "A": "Training an NLP model on a very small dataset.",
      "B": "The ability of an NLP model to perform a task (e.g., sentiment analysis for a new product category) or answer questions about entities that it has never explicitly seen during training, by leveraging semantic knowledge (e.g., word embeddings, pre-trained language models) to infer relationships.",
      "C": "Generating text without any input prompt.",
      "D": "Translating text into a language for which no data exists."
    },
    "answer": "B",
    "explanation": "Zero-shot learning is a crucial step towards building truly intelligent NLP systems that can generalize to new concepts and tasks without requiring new labeled data for every single instance.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 266,
    "question": "What is the 'Manifold Hypothesis' in deep learning, and how does it relate to the success of deep generative models?",
    "options": {
      "A": "It states that all data lies on a single, linear manifold.",
      "B": "The hypothesis posits that high-dimensional data (e.g., images, text) often resides on or close to a low-dimensional manifold embedded in the higher-dimensional space. Deep generative models (like VAEs, GANs, Diffusion Models) leverage this by learning to map from a simple low-dimensional latent space (the learned manifold) to the complex data distribution, enabling the generation of realistic and diverse samples.",
      "C": "It's a theory about the optimal number of layers in a GAN.",
      "D": "It suggests that data can only be represented in a discrete manner."
    },
    "answer": "B",
    "explanation": "The manifold hypothesis provides a theoretical underpinning for why deep learning is so effective at learning compact and meaningful representations from complex, high-dimensional data.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 267,
    "question": "How do 'Equivariant Neural Networks' explicitly leverage group symmetries in data, and what practical advantages do they offer?",
    "options": {
      "A": "They ignore symmetries, focusing on brute-force learning.",
      "B": "Equivariant NNs are constructed such that their operations (e.g., convolutions, pooling) are designed to commute with certain transformations (e.g., rotations, translations), meaning if the input is transformed, the output transforms predictably. This hardcodes knowledge of symmetries, leading to increased parameter efficiency, reduced data requirements, and improved generalization, especially for tasks with inherent symmetries like medical image analysis or molecular modeling.",
      "C": "They require a separate transformation layer for each symmetry.",
      "D": "They can only detect symmetries that are perfectly linear."
    },
    "answer": "B",
    "explanation": "Equivariant networks represent a principled approach to building more robust and data-efficient models by incorporating fundamental symmetries present in the data.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 268,
    "question": "What is 'Curriculum Learning' and what are its potential benefits for training deep neural networks?",
    "options": {
      "A": "Training on a fixed set of data for a fixed number of epochs.",
      "B": "A training strategy inspired by cognitive science, where a model is presented with easier examples or tasks first, gradually increasing the complexity as it learns. This can lead to faster convergence, better final performance (escaping poor local minima), and improved generalization, especially for complex or noisy datasets.",
      "C": "Randomly shuffling the training data after each epoch.",
      "D": "A method to reduce the number of parameters in a network."
    },
    "answer": "B",
    "explanation": "Curriculum learning can be viewed as a form of annealing, guiding the optimizer through the loss landscape more effectively by starting with simpler learning problems.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 269,
    "question": "What is 'Disentangled Representation Learning' and what are its main advantages for generative models and interpretability?",
    "options": {
      "A": "Learning representations where features are highly correlated.",
      "B": "It aims to learn representations where different latent dimensions correspond to distinct, independent, and interpretable factors of variation in the data (e.g., color, shape, size, lighting). This is desirable for controlling generation, improving model interpretability, enabling fair AI, and enhancing transferability across tasks.",
      "C": "Representations that are always linear and easy to understand.",
      "D": "Representations that are randomly generated for each sample."
    },
    "answer": "B",
    "explanation": "Disentangled representations are a crucial step towards more controllable, interpretable, and robust generative AI, allowing for targeted manipulation of specific attributes in generated content.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 270,
    "question": "How do 'Recurrent Convolutional Neural Networks (RCNNs)' leverage both spatial and temporal dependencies?",
    "options": {
      "A": "RCNNs only use CNNs for temporal processing.",
      "B": "RCNNs integrate convolutional layers (for extracting spatial features from individual frames/regions) with recurrent layers (like LSTMs or GRUs, for modeling temporal dependencies across sequences of frames/regions). This combined architecture is particularly effective for tasks involving both visual patterns and their evolution over time, such as video analysis, action recognition, or scene understanding.",
      "C": "RCNNs remove all recurrent connections, relying only on convolutions.",
      "D": "RCNNs are designed solely for static image classification."
    },
    "answer": "B",
    "explanation": "RCNNs are well-suited for processing spatio-temporal data, allowing them to learn complex patterns in videos, medical imaging sequences, or structured documents.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 271,
    "question": "What is 'Out-of-Distribution (OOD) Detection' and why is it critically important for safe AI deployment?",
    "options": {
      "A": "Detecting anomalies in the training data itself.",
      "B": "It's the task of identifying when a model is presented with input data that significantly deviates from its training distribution. This is crucial for safety-critical applications because deep learning models tend to make overconfident and potentially dangerous incorrect predictions when faced with data outside their learned domain, which OOD detection helps to flag.",
      "C": "Detecting when a model is predicting values that are outside the expected numerical range.",
      "D": "Detecting if a model has been trained on publicly available data only."
    },
    "answer": "B",
    "explanation": "OOD detection is a core component of building reliable and trustworthy AI systems that know their limitations and can alert users when they encounter unfamiliar scenarios.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 272,
    "question": "Explain the 'Gumbel-Softmax Trick' and its application in models that require discrete sampling and gradient-based optimization.",
    "options": {
      "A": "A trick to make continuous distributions discrete.",
      "B": "The Gumbel-Softmax trick provides a differentiable approximation to sampling from a discrete categorical distribution. By introducing Gumbel noise and using the softmax function, it allows the gradients to flow through discrete latent variables, enabling end-to-end training of generative models (e.g., VAEs for discrete data, text generation) that involve sampling discrete tokens.",
      "C": "A method to smooth out very sharp probability distributions.",
      "D": "A way to increase the number of discrete categories in a model."
    },
    "answer": "B",
    "explanation": "This trick is fundamental for integrating discrete decision-making processes into differentiable deep learning architectures, expanding the range of problems that can be tackled with gradient descent.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 273,
    "question": "What is the primary contribution of the 'Transformer' architecture to sequence modeling?",
    "options": {
      "A": "It introduced recurrent connections for better memory.",
      "B": "It completely eliminated the need for recurrent (RNNs) and convolutional (CNNs) layers for sequence processing, relying solely on 'self-attention' mechanisms. This enabled parallel computation of dependencies across an entire sequence, leading to unprecedented efficiency and ability to model long-range contexts, revolutionizing NLP and extending to vision.",
      "C": "It significantly reduced the number of parameters compared to RNNs.",
      "D": "It only works with very short sequences of data."
    },
    "answer": "B",
    "explanation": "The Transformer's architecture, particularly its self-attention, has become the dominant paradigm for sequential data processing due to its parallelizability and effectiveness in capturing long-range dependencies.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 274,
    "question": "How does 'Reinforcement Learning from Scratch' differ from 'Reinforcement Learning with Pre-trained Models' in sample efficiency?",
    "options": {
      "A": "RL from scratch is always more sample efficient.",
      "B": "RL from scratch trains an agent from random initialization, which typically requires a vast number of interactions with the environment (low sample efficiency) to learn effective policies. RL with pre-trained models (e.g., using a backbone from self-supervised learning) can be significantly more sample-efficient as it leverages rich, pre-learned representations, reducing the amount of environmental interaction needed for effective learning.",
      "C": "RL with pre-trained models is only for simulated environments.",
      "D": "Sample efficiency is irrelevant in deep reinforcement learning."
    },
    "answer": "B",
    "explanation": "Leveraging pre-trained knowledge is a major trend in RL, addressing one of its most significant challenges: the high cost of data collection and environmental interaction.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 275,
    "question": "Explain 'Knowledge Graph Embeddings' and their utility in reasoning and recommendation systems.",
    "options": {
      "A": "Embedding text documents into a graph structure.",
      "B": "Representing entities (nodes) and relations (edges) within a knowledge graph as continuous, low-dimensional vectors in an embedding space. This allows for computational reasoning (e.g., predicting missing links, answering queries) by performing vector operations and measuring distances, improving recommendation systems by capturing complex entity relationships.",
      "C": "A method for visualizing large knowledge graphs.",
      "D": "Converting images into a graph format for deep learning."
    },
    "answer": "B",
    "explanation": "Knowledge Graph Embeddings bridge the gap between structured knowledge and deep learning, enabling sophisticated reasoning and powerful applications in various domains.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 276,
    "question": "What is the challenge of 'Catastrophic Forgetting' in Continual Learning, and what are some strategies to mitigate it?",
    "options": {
      "A": "The model forgets its initial random weights.",
      "B": "Catastrophic forgetting refers to the phenomenon where a neural network rapidly loses its ability to perform previously learned tasks when it is trained on new tasks. Mitigation strategies include 'regularization-based' (e.g., Elastic Weight Consolidation - EWC, Synaptic Intelligence), 'rehearsal/replay-based' (e.g., storing and re-training on a small subset of old data), and 'parameter isolation/expansion' methods.",
      "C": "The model forgets what the input data represents.",
      "D": "The model forgets how to update its parameters."
    },
    "answer": "B",
    "explanation": "Overcoming catastrophic forgetting is a fundamental problem in developing AI systems that can learn and adapt over long periods in dynamic environments, mimicking human-like continuous learning.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 277,
    "question": "How do 'Hypernetworks' allow for more dynamic and adaptive weight generation in deep learning models?",
    "options": {
      "A": "They increase the size of the main network's input layer.",
      "B": "A hypernetwork is a neural network that generates the weights (or parameters) for another neural network (the 'main network'). This allows the main network's parameters to be dynamically conditioned on various inputs (e.g., task descriptors, latent codes, meta-learning objectives), enabling a single hypernetwork to generate many different specialized main networks.",
      "C": "They are used to optimize the learning rate during training.",
      "D": "They always produce sparser weights than direct weight initialization."
    },
    "answer": "B",
    "explanation": "Hypernetworks offer a powerful mechanism for creating highly flexible models that can adapt their structure or behavior in response to external conditions or specific task requirements.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 278,
    "question": "What is the theoretical significance of the 'Universal Approximation Theorem' for deep learning, and what does it NOT guarantee?",
    "options": {
      "A": "It guarantees that a network will train efficiently.",
      "B": "The theorem states that a feedforward neural network with a single hidden layer and a non-linear activation function can approximate any continuous function to arbitrary accuracy. It signifies the theoretical expressive power of ANNs. However, it *does not guarantee* that the network can *learn* this function efficiently from data, or that a deep network is easier to train or generalize better than a shallow one for a given task.",
      "C": "It guarantees that any function can be represented by a linear model.",
      "D": "It proves that deep networks always converge to the global minimum."
    },
    "answer": "B",
    "explanation": "While the theorem confirms the expressive power of neural networks, the practical challenges of learning and generalization in deep, non-convex landscapes remain a significant area of research.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 279,
    "question": "Explain 'Self-Supervised Learning' in Natural Language Processing (NLP) with an example of a 'pretext task'.",
    "options": {
      "A": "Training NLP models using explicit human annotations.",
      "B": "Self-supervised learning in NLP involves training models on large amounts of unlabeled text data by creating 'pretext tasks' where the supervision signal is derived automatically from the input itself. Example pretext tasks include 'masked language modeling' (predicting masked words, like BERT) or 'next sentence prediction'. This allows learning rich word/sentence embeddings that are then fine-tuned for downstream tasks.",
      "C": "Learning from only a single sentence.",
      "D": "Generating new text by mimicking human writing style."
    },
    "answer": "B",
    "explanation": "Self-supervised learning has been transformative for NLP, enabling the creation of powerful pre-trained language models that achieve state-of-the-art results across a wide range of tasks with reduced reliance on task-specific labeled data.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  },
  {
    "id": 280,
    "question": "What is the significance of the 'Neural Tangent Kernel (NTK)' in providing theoretical guarantees for deep learning?",
    "options": {
      "A": "NTK allows for exact calculation of the global minimum.",
      "B": "For infinitely wide neural networks trained with gradient descent, the NTK allows one to precisely characterize the network's behavior and performance as a linear model in feature space. This provides a rare instance of theoretical tractability for deep learning, offering insights into generalization and optimization properties in this specific regime.",
      "C": "NTK provides a way to reduce model complexity significantly.",
      "D": "NTK proves that all neural networks will always overfit."
    },
    "answer": "B",
    "explanation": "NTK theory is a significant step towards a more rigorous theoretical understanding of deep learning, especially for the increasingly common phenomenon of overparameterized models.",
    "topic": "Deep Learning",
    "difficulty": "Hard"
  }
]